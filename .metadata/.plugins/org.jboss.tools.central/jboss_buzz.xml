<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title>The .NET Process class on Linux</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/7RKu3QxnZDw/" /><category term=".net" scheme="searchisko:content:tags" /><category term=".NET Core" scheme="searchisko:content:tags" /><category term=".NET Core 3.0" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="linux" scheme="searchisko:content:tags" /><author><name>Tom Deseyn</name></author><id>searchisko:content:id:jbossorg_blog-the_net_process_class_on_linux</id><updated>2019-10-29T07:00:45Z</updated><published>2019-10-29T07:00:45Z</published><content type="html">&lt;p&gt;In this article, we&amp;#8217;ll look at .NET&amp;#8217;s &lt;code&gt;Process&lt;/code&gt; class. We&amp;#8217;ll go over the basics of how and when to use it, then cover differences in usage between Windows and Linux, and point out a few caveats. This article covers behavior in &lt;a href="https://developers.redhat.com/blog/2019/10/17/new-features-in-net-core-3-0-on-linux/"&gt;.NET Core 3.0&lt;/a&gt;.&lt;span id="more-640327"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;The basics&lt;/h2&gt; &lt;p&gt;The &lt;a href="https://docs.microsoft.com/en-us/dotnet/api/system.diagnostics.process?view=netcore-3.0"&gt;Process&lt;/a&gt; class represents an instance of a running process. You can use it to start new processes using &lt;code&gt;Process.Start&lt;/code&gt; or get running processes via the static &lt;code&gt;GetProcessById&lt;/code&gt;,&lt;code&gt;GetProcesses&lt;/code&gt;,&lt;code&gt;GetProcessesByName&lt;/code&gt; methods.&lt;/p&gt; &lt;p&gt;When starting a new &lt;code&gt;Process&lt;/code&gt;, all information to start the process is set on a &lt;code&gt;ProcessStartInfo&lt;/code&gt; instance (PSI). PSI has properties like &lt;code&gt;FileName&lt;/code&gt; and &lt;code&gt;Arguments&lt;/code&gt; to set the program to execute and its arguments. &lt;code&gt;UseShellExecute&lt;/code&gt; allows you to open documents. &lt;code&gt;RedirectStandard{Input/Output/Error}&lt;/code&gt; allows you to write/read the standard I/O streams. &lt;code&gt;Environment&lt;/code&gt;/&lt;code&gt;EnvironmentVariables&lt;/code&gt; and &lt;code&gt;WorkingDirectory&lt;/code&gt; allow you to control the environment variables and working directory.&lt;/p&gt; &lt;p&gt;.NET Core 2.1 (/netstandard 2.1) added an &lt;code&gt;ArgumentList&lt;/code&gt; property. The &lt;code&gt;Arguments&lt;/code&gt; property is a string and requires the user to use &lt;a href="https://docs.microsoft.com/en-us/cpp/cpp/parsing-cpp-command-line-arguments?view=vs-2019"&gt;Windows command-line escaping rules&lt;/a&gt; (e.g., using double-quotes to delimit arguments). The &lt;code&gt;ArgumentsList&lt;/code&gt; property is a &lt;code&gt;Collection&lt;/code&gt; that holds separate arguments. &lt;code&gt;Process.Start&lt;/code&gt; will take care of passing those to the underlying platform. It&amp;#8217;s recommended to use &lt;code&gt;ArgumentList&lt;/code&gt; over &lt;code&gt;Arguments&lt;/code&gt; when targeting .NET Core 2.1+/netstandard2.1+.&lt;/p&gt; &lt;p&gt;The following example shows launching the &lt;code&gt;echo&lt;/code&gt; application, with a single argument &lt;em&gt;hello world&lt;/em&gt;, and then waiting for the process to terminate.&lt;/p&gt; &lt;pre&gt;using var process = Process.Start( new ProcessStartInfo { FileName = "echo", ArgumentList = { "hello world" } }); process.WaitForExit(); &lt;/pre&gt; &lt;h2&gt;Not supported on Linux&lt;/h2&gt; &lt;p&gt;The following properties of &lt;code&gt;ProcessStartInfo&lt;/code&gt; aren&amp;#8217;t supported on Linux and throw &lt;code&gt;PlatformNotSupportedException&lt;/code&gt;: &lt;code&gt;PasswordInClearText&lt;/code&gt;, &lt;code&gt;Domain&lt;/code&gt;, &lt;code&gt;LoadUserProfile&lt;/code&gt;, &lt;code&gt;Password&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;Retrieving processes from a remote machine using the &lt;code&gt;machineName&lt;/code&gt; overload &lt;code&gt;GetProcessById&lt;/code&gt;,&lt;code&gt;GetProcesses&lt;/code&gt;,&lt;code&gt;GetProcessesByName&lt;/code&gt; is also not supported.&lt;/p&gt; &lt;p&gt;On the &lt;code&gt;Process&lt;/code&gt;, it isn&amp;#8217;t supported to set working set limits (&lt;code&gt;MinWorkingSet&lt;/code&gt;, &lt;code&gt;MaxWorkingSet&lt;/code&gt;). On a &lt;code&gt;ProcessThread&lt;/code&gt; (obtained via &lt;code&gt;Process.Threads&lt;/code&gt;) the &lt;code&gt;PriorityLevel&lt;/code&gt;/&lt;code&gt;ProcessorAffinity&lt;/code&gt; cannot be set.&lt;/p&gt; &lt;h2&gt;Killing processes&lt;/h2&gt; &lt;p&gt;Processes can be stopped by calling &lt;code&gt;Process.Kill&lt;/code&gt;. On Linux, this is implemented by sending the &lt;code&gt;SIGKILL&lt;/code&gt; signal, which tells the kernel to terminate the application immediately. It’s not possible to send a &lt;code&gt;SIGTERM&lt;/code&gt; signal, which requests the application to gracefully terminate.&lt;/p&gt; &lt;p&gt;Since .NET Core 3.0, &lt;code&gt;Process.Kill&lt;/code&gt; no longer throws &lt;code&gt;Win32Exception&lt;/code&gt;/&lt;code&gt;InvalidOperationException&lt;/code&gt; if the process is terminating or was already terminated. If you are targeting earlier .NET Core versions (or .NET Framework), you should add a &lt;code&gt;try/catch&lt;/code&gt; block to handle these exceptions.&lt;/p&gt; &lt;p&gt;.NET Core 3.0 adds an overload to the &lt;code&gt;Process.Kill&lt;/code&gt; method that accepts a bool &lt;code&gt;entireProcessTree&lt;/code&gt;. When set to &lt;code&gt;true&lt;/code&gt;, descendants of the process will also be killed.&lt;/p&gt; &lt;h2&gt;UseShellExecute&lt;/h2&gt; &lt;p&gt;The &lt;code&gt;ProcessStartInfo.UseShellExecute&lt;/code&gt; property can be used to open documents. &lt;em&gt;Shell&lt;/em&gt; refers to the graphical shell of the user, and not a command-line shell like &lt;code&gt;bash&lt;/code&gt;. Setting this to &lt;code&gt;true&lt;/code&gt; means b&lt;em&gt;ehave as if the user double-clicks the file&lt;/em&gt;. When &lt;code&gt;ProcessStartInfo.FileName&lt;/code&gt; refers to an executable, it will be executed. When it refers to a document, it will be opened using the default program. For example an &lt;code&gt;.ods&lt;/code&gt; file will open with &lt;em&gt;LibreOffice Calc&lt;/em&gt;. You can set &lt;code&gt;FileName&lt;/code&gt; to an http-uri (like &lt;em&gt;https://redhatloves.net&lt;/em&gt;) to open up a browser and show a website.&lt;/p&gt; &lt;p&gt;Unix shell scripts are considered real executables by the operating system (OS). This means it is not required to set &lt;code&gt;UseShellExecute&lt;/code&gt;. This approach is unlike Windows &lt;code&gt;.bat&lt;/code&gt; files, which need the Windows shell to find the interpreter.&lt;/p&gt; &lt;p&gt;On Windows, &lt;code&gt;UseShellExecute&lt;/code&gt; allows alternative actions on a document (like printing) by setting the &lt;code&gt;ProcessStartInfo.Verb&lt;/code&gt;. On other OSes, this property is ignored.&lt;/p&gt; &lt;h2&gt;FileName resolution&lt;/h2&gt; &lt;p&gt;When setting a relative filename on &lt;code&gt;Process.FileName&lt;/code&gt;, the file will be resolved. The resolution steps depend on &lt;code&gt;UseShellExecute&lt;/code&gt; being set or not. The resolution on non-Windows platforms is implemented to behave similarly to Windows.&lt;/p&gt; &lt;p&gt;When &lt;code&gt;UseShellExecute&lt;/code&gt; is set to &lt;code&gt;false&lt;/code&gt;:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Find the file in the native application directory.&lt;/li&gt; &lt;li&gt;Find the file in the process&amp;#8217;s working directory.&lt;/li&gt; &lt;li&gt;Find the file on PATH.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;The native application directory is the &lt;code&gt;dotnet&lt;/code&gt; installation directory when executing &lt;em&gt;dotnet&lt;/em&gt;. When using a native apphost, it’s the apphost directory.&lt;/p&gt; &lt;p&gt;When &lt;code&gt;UseShellExecute&lt;/code&gt; is set to &lt;code&gt;true&lt;/code&gt;:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Find an executable file in the &lt;code&gt;ProcessStartInfo.WorkingDirectory&lt;/code&gt;. If that is not set, the process working directory is used.&lt;/li&gt; &lt;li&gt;Find an executable file on PATH.&lt;/li&gt; &lt;li&gt;Use the shell &lt;code&gt;open&lt;/code&gt; program and pass it the relative path.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;It&amp;#8217;s important to know that in both cases directories are searched, which may be unsafe (executable directory, working directory). You may want to implement your own resolution and always set &lt;code&gt;FileName&lt;/code&gt; to an absolute path.&lt;/p&gt; &lt;h2&gt;Redirected streams&lt;/h2&gt; &lt;p&gt;When &lt;code&gt;UseShellExecute&lt;/code&gt; is set to &lt;code&gt;false&lt;/code&gt;, you can redirect standard input, output, and error using &lt;code&gt;ProcessStartInfo.RedirectStandard{Input/Output/Error}&lt;/code&gt;. Corresponding &lt;code&gt;Encoding&lt;/code&gt; properties (like &lt;code&gt;StandardOutputEncoding&lt;/code&gt;) allow you to set the encoding for the streams.&lt;/p&gt; &lt;p&gt;Unless you&amp;#8217;re running or starting an interactive application (like launching &lt;code&gt;vi&lt;/code&gt;), you should redirect the streams and handle them.&lt;/p&gt; &lt;p&gt;Note that asynchronous methods like &lt;code&gt;Process.StandardOutput.ReadAsync&lt;/code&gt; and &lt;code&gt;Process.BeginOutputReadLine&lt;/code&gt; use the &lt;code&gt;ThreadPool&lt;/code&gt; to do asynchronous reads, which means they block a &lt;code&gt;ThreadPool&lt;/code&gt; thread when waiting for application output. This approach can lead to &lt;code&gt;ThreadPool&lt;/code&gt; starvation if you have many &lt;code&gt;Processes&lt;/code&gt; that don’t output much. This is an issue on Windows, too.&lt;/p&gt; &lt;p&gt;If you are using &lt;code&gt;Begin{Output/Error}ReadLine&lt;/code&gt; and call &lt;code&gt;WaitForExit&lt;/code&gt;, that method will wait until all standard output/error was read (and corresponding &lt;code&gt;{Output/Error}DataReceived&lt;/code&gt; events are emitted). This approach can cause the call to block for a process that has exited when there are descendants that are keeping the redirected streams open.&lt;/p&gt; &lt;h2&gt;ProcessName&lt;/h2&gt; &lt;p&gt;On Linux, when executing a shell script, &lt;code&gt;Process.ProcessName&lt;/code&gt; holds the name of the script. Similarly, &lt;code&gt;Process.GetProcessesByName&lt;/code&gt; will match script names. This capability is useful to identify processes regardless of whether they are native executables, scripts, or scripts wrapping native executables.&lt;/p&gt; &lt;h2&gt;Process exit&lt;/h2&gt; &lt;p&gt;Processes hold up some resources in the kernel. On Windows, this information is reference counted, which allows multiple users to keep the information alive using a &lt;a href="https://docs.microsoft.com/en-us/windows/win32/procthread/process-handles-and-identifiers"&gt;Process Handle&lt;/a&gt;. On Unix, there is a single owner of this information. First, it is the parent process, and when the parent dies, it is the &lt;code&gt;init&lt;/code&gt; (pid 1) process (or a process that assumed this responsibility using &lt;a href="http://man7.org/linux/man-pages/man2/prctl.2.html"&gt;PR_SET_CHILD_SUBREAPER&lt;/a&gt;). The owning process is the process responsible for cleaning up the kernel resources (aka reaping the child). .NET Core reaps child processes as soon as they terminate.&lt;/p&gt; &lt;p&gt;When the resources are cleaned up, the information about the process can no longer be retrieved. Properties that return runtime information throw &lt;code&gt;InvalidOperationException&lt;/code&gt; at that point. On Windows, you can retrieve &lt;code&gt;StartTime&lt;/code&gt;, &lt;code&gt;{Privileged,Total,User}ProcessorTime&lt;/code&gt; after the process exited. On Linux, these properties throw &lt;code&gt;InvalidOperationException&lt;/code&gt; also.&lt;/p&gt; &lt;p&gt;On Linux, the &lt;code&gt;Process.ExitCode&lt;/code&gt; is valid only for direct children. For other processes, it returns &lt;code&gt;0&lt;/code&gt; or throws &lt;code&gt;InvalidOperationException&lt;/code&gt; depending on the state of the &lt;code&gt;Process&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;If you are running in a container, often there is no init process. This means that no one is reaping orphaned children. Such child processes will keep consuming kernel resources, and .NET Core will never consider them exited. This issue occurs when an application has descendants that out-live their parents. If you are in this case, you should add an init process to your container. When using &lt;code&gt;docker/podman run&lt;/code&gt;, you can add one using the &lt;code&gt;--init&lt;/code&gt; flag.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;In this article, we explained the behavior of .NET’s Process class on Linux. We covered basic use, non-supported behavior, differences with Windows, and other things to be aware of.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F29%2Fthe-net-process-class-on-linux%2F&amp;#38;linkname=The%20.NET%20Process%20class%20on%20Linux" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F29%2Fthe-net-process-class-on-linux%2F&amp;#38;linkname=The%20.NET%20Process%20class%20on%20Linux" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F29%2Fthe-net-process-class-on-linux%2F&amp;#38;linkname=The%20.NET%20Process%20class%20on%20Linux" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F29%2Fthe-net-process-class-on-linux%2F&amp;#38;linkname=The%20.NET%20Process%20class%20on%20Linux" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F29%2Fthe-net-process-class-on-linux%2F&amp;#38;linkname=The%20.NET%20Process%20class%20on%20Linux" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F29%2Fthe-net-process-class-on-linux%2F&amp;#38;linkname=The%20.NET%20Process%20class%20on%20Linux" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F29%2Fthe-net-process-class-on-linux%2F&amp;#38;linkname=The%20.NET%20Process%20class%20on%20Linux" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F29%2Fthe-net-process-class-on-linux%2F&amp;#038;title=The%20.NET%20Process%20class%20on%20Linux" data-a2a-url="https://developers.redhat.com/blog/2019/10/29/the-net-process-class-on-linux/" data-a2a-title="The .NET Process class on Linux"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/10/29/the-net-process-class-on-linux/"&gt;The .NET Process class on Linux&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/7RKu3QxnZDw" height="1" width="1" alt=""/&gt;</content><summary>In this article, we’ll look at .NET’s Process class. We’ll go over the basics of how and when to use it, then cover differences in usage between Windows and Linux, and point out a few caveats. This article covers behavior in .NET Core 3.0. The basics The Process class represents an instance of a running process. You can use it to start new processes using Process.Start or get running processes via...</summary><dc:creator>Tom Deseyn</dc:creator><dc:date>2019-10-29T07:00:45Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2019/10/29/the-net-process-class-on-linux/</feedburner:origLink></entry><entry><title>Verifying signatures of Red Hat container images</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/5FkPUU4DLWc/" /><category term="Containers" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="linux" scheme="searchisko:content:tags" /><category term="openshift" scheme="searchisko:content:tags" /><category term="Podman" scheme="searchisko:content:tags" /><category term="Red Hat OpenShift Container Platform" scheme="searchisko:content:tags" /><category term="security" scheme="searchisko:content:tags" /><category term="skopeo" scheme="searchisko:content:tags" /><category term="Universal Base Images (UBI)" scheme="searchisko:content:tags" /><author><name>Fernando Lozano</name></author><id>searchisko:content:id:jbossorg_blog-verifying_signatures_of_red_hat_container_images</id><updated>2019-10-29T06:59:46Z</updated><published>2019-10-29T06:59:46Z</published><content type="html">&lt;p&gt;Security-conscious organizations are accustomed to using digital signatures to validate application content from the Internet. A common example is RPM package signing. &lt;a href="https://developers.redhat.com/rhel8/"&gt;Red Hat Enterprise Linux (RHEL)&lt;/a&gt; validates signatures of RPM packages by default.&lt;/p&gt; &lt;p&gt;In the container world, a similar paradigm should be adhered to. In fact, all container images from Red Hat have been digitally signed and have been for several years. Many users are not aware of this because early container tooling was not designed to support digital signatures.&lt;/p&gt; &lt;p&gt;In this article, I&amp;#8217;ll demonstrate how to configure a container engine to validate signatures of container images from the Red Hat registries for increased security of your containerized applications.&lt;span id="more-642307"&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;In the lack of widely accepted standards, Red Hat designed a simple approach to provide security to its customers. This approach is based on &lt;i&gt;detached signatures&lt;/i&gt; served by a standard HTTP server. The Linux container tools (&lt;a href="https://developers.redhat.com/blog/2019/04/25/podman-basics-cheat-sheet/"&gt;Podman&lt;/a&gt;, Skopeo, and &lt;a href="https://developers.redhat.com/blog/2019/02/21/podman-and-buildah-for-docker-users/"&gt;Buildah&lt;/a&gt;) have built-in support for detached signatures, as well as the CRI-O container engine from &lt;a href="https://developers.redhat.com/topics/kubernetes/"&gt;Kubernetes&lt;/a&gt; and the &lt;a href="https://developers.redhat.com/products/openshift/overview"&gt;Red Hat OpenShift Container Platform&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Configuring Linux container tools to check image signatures&lt;/h2&gt; &lt;p&gt;Configuring Linux container tools to only run container images that pass signature checking is a two-step process:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Create a YAML file under &lt;code&gt;/etc/containers/registries.d&lt;/code&gt; that specifies the location of detached signatures for a given registry server.&lt;/li&gt; &lt;li&gt;Add an entry to &lt;code&gt;/etc/containers/policy.json&lt;/code&gt; that specifies the public GPG key that validates signatures of a given registry server.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Red Hat stores signatures for its container images at &lt;a href="https://access.redhat.com/webassets/docker/content/sigstore"&gt;https://access.redhat.com/webassets/docker/content/sigstore&lt;/a&gt;. Red Hat signs its images with the same GPG key it uses to sign RPM packages. All Red Hat Enterprise Linux (RHEL) systems ship with Red Hat’s RPM public key at &lt;code&gt;/etc/pki/rpm-gpg/RPM-GPG-KEY-redhat-release&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;With the information above, you can create the &lt;code&gt;/etc/containers/registries.d/redhat.yaml&lt;/code&gt; file with the following content:&lt;/p&gt; &lt;pre&gt;docker:   registry.access.redhat.com:     sigstore: https://access.redhat.com/webassets/docker/content/sigstore&lt;/pre&gt; &lt;p&gt;And, you can edit your &lt;code&gt;/etc/containers/policy.json&lt;/code&gt; as follows:&lt;/p&gt; &lt;pre&gt;{   "default": [     {       "type": "insecureAcceptAnything"     }   ],   "transports":     {       "docker-daemon":         {           "": [{"type":"insecureAcceptAnything"}]         },       "docker":         {           "registry.access.redhat.com": [             {               "type": "signedBy",               "keyType": "GPGKeys",               "keyPath": "/etc/pki/rpm-gpg/RPM-GPG-KEY-redhat-release"             }           ]         }     } }&lt;/pre&gt; &lt;h2&gt;Testing that Linux container tools refuse images that fail signature check&lt;/h2&gt; &lt;p&gt;An easy way to validate your settings is by starting a container using the &lt;a href="https://developers.redhat.com/blog/2019/10/09/what-is-red-hat-universal-base-image/"&gt;Red Hat Universal Base Image (UBI)&lt;/a&gt;. If the following command fails, you may have made a mistake editing your container runtime configuration files:&lt;/p&gt; &lt;pre&gt;$ sudo podman run --rm --name test registry.access.redhat.com/ubi8/ubi:8.0-199 date Trying to pull registry.access.redhat.com/ubi8/ubi:8.0-199...Getting image source signatures Checking if image destination supports signatures Copying blob 567fcfc2ff35: 67.77 MiB / 67.77 MiB [=========================] 56s Copying blob 188d0510bf14: 1.48 KiB / 1.48 KiB [===========================] 56s Copying config a73bf97264a0: 4.43 KiB / 4.43 KiB [==========================] 0s Writing manifest to image destination Storing signatures Sat Oct  5 17:24:31 UTC 2019&lt;/pre&gt; &lt;p&gt;The output from Podman appears similar to the result that you would get without configuring signature checking. One way to confirm that signatures are actually being validated is to force a validation error by specifying an incorrect GPG key.&lt;/p&gt; &lt;p&gt;If you have the EPEL repository configured on your system, you can edit &lt;code&gt;/etc/containers/policy.json&lt;/code&gt; as follows to use the GPG key from that repository:&lt;/p&gt; &lt;pre&gt;...       "docker":         {           "registry.access.redhat.com": [             {               "type": "signedBy",               "keyType": "GPGKeys",               "keyPath": "/etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-8"             }           ]         } ...&lt;/pre&gt; &lt;p&gt;Remove the container image you already downloaded:&lt;/p&gt; &lt;pre&gt;$ sudo podman rmi registry.access.redhat.com/ubi8/ubi:8.0-199&lt;/pre&gt; &lt;p&gt;And try starting a new container. Now it fails because the container image signature does not match the GPG key:&lt;/p&gt; &lt;pre&gt;$ sudo podman run --rm --name test \ registry.access.redhat.com/ubi8/ubi:8.0-199 date Trying to pull registry.access.redhat.com/ubi8/ubi:8.0-199...Failed unable to pull registry.access.redhat.com/ubi8/ubi:8.0-199: unable to pull image: Source image rejected: None of the signatures were accepted, reasons: Invalid GPG signature: ...&lt;/pre&gt; &lt;p&gt;The error message is actually much longer and scarier. I only show the first few lines of the message, but it is clear why Podman was unable to pull the image.&lt;/p&gt; &lt;p&gt;After this test, remember to fix your &lt;code&gt;/etc/containers/policy.json&lt;/code&gt; so it specifies the correct GPG key for Red Hat container images and RHEL RPM packages.&lt;/p&gt; &lt;h2&gt;Validating detached image signatures with rootless containers&lt;/h2&gt; &lt;p&gt;Note that my previous commands use &lt;code&gt;sudo&lt;/code&gt; to run &lt;code&gt;podman&lt;/code&gt;. This is how you would perform these tasks on RHEL and CentOS up to 7.6 along with older Fedora releases. Non-RHEL systems will not include the public GPG key to validate RHEL packages. These keys can be downloaded from the &lt;a href="https://access.redhat.com/"&gt;Red Hat Customer Portal&lt;/a&gt; [1].&lt;/p&gt; &lt;p&gt;If you are on a very recent RHEL, CentOS, or Fedora release, you probably have support for rootless containers [2]. This means you do not need to use &lt;code&gt;sudo&lt;/code&gt; anymore. The configuration file changes remain the same.&lt;/p&gt; &lt;h2&gt;Mirroring Red Hat container images to a private registry&lt;/h2&gt; &lt;p&gt;Many organizations do not allow their servers to download application content directly from the Internet, regardless of whether the content originates from a trusted vendor and is digitally signed. These organizations typically deploy a private registry server internally and require that its servers, and sometimes its developers, to only pull container images from this location.&lt;/p&gt; &lt;p&gt;To emulate that scenario, I will copy the UBI container image to my personal account at Quay.io and configure my container runtime to check image signatures for images stored there. I will store my detached signatures into a local folder to avoid the need to set up an HTTP server.&lt;/p&gt; &lt;p&gt;When you copy container images between registry servers, you cannot just copy their detached signatures, too. These signatures are tied to the full container image reference, which includes the registry name. So, the signatures from Red Hat become invalid for their copies on a private registry.&lt;/p&gt; &lt;p&gt;One way to solve that issue is to use a private GPG key that your organization owns. Then, you copy the public GPG key to any server and developer workstation that needs it. To keep things simple, I will use my personal GPG key pair that I already use to sign email. If it is your first time working with GPG, see the references section [3] for a nice tutorial about generating your GPG key pair.&lt;/p&gt; &lt;p&gt;Fortunately, the signing process is very easy, and it is handled by the same &lt;code&gt;skopeo copy&lt;/code&gt; command you would use to mirror the image into your private registry.&lt;/p&gt; &lt;h2&gt;Signing container images&lt;/h2&gt; &lt;p&gt;Create the &lt;code&gt;/etc/containers/registries.d/quayio.yaml&lt;/code&gt; file with the following content, and replace “flozanorht” with your account at Quay.io:&lt;/p&gt; &lt;pre&gt;docker:   quay.io/flozanorht/ubi:     sigstore: file:///var/lib/atomic/sigstore/     sigstore-staging: file:///var/lib/atomic/sigstore/&lt;/pre&gt; &lt;p&gt;You need to either give your user permission to write to the &lt;code&gt;/var/lib/atomic/sigstore/&lt;/code&gt; or pick a different folder.&lt;/p&gt; &lt;p&gt;Then, edit your &lt;code&gt;/etc/containers/policy.json&lt;/code&gt; file as follows:&lt;/p&gt; &lt;pre&gt;...       "docker":         {           "registry.access.redhat.com": [             {               "type": "signedBy",               "keyType": "GPGKeys",               "keyPath": "/etc/pki/rpm-gpg/RPM-GPG-KEY-redhat-release"             }           ],           "quay.io/flozanorht/ubi": [             {               "type": "signedBy",               "keyType": "GPGKeys",               "keyPath": "/etc/pki/rpm-gpg/flozano-pub"             }           ]         } ...&lt;/pre&gt; &lt;p&gt;To export my GPG public key to &lt;code&gt;/etc/pki/rpm-gpg/flozano-pub&lt;/code&gt;, I ran the following command:&lt;/p&gt; &lt;pre&gt;$ gpg --export --armor flozano@redhat.com &amp;#62; /tmp/flozano-pub $ sudo mv /tmp/flozano-pub /etc/pki/rpm-gpg/flozano-pub&lt;/pre&gt; &lt;p&gt;And, finally, to mirror the UBI image, the &lt;code&gt;skopeo copy&lt;/code&gt; command needs the &lt;code&gt;--remove-signatures&lt;/code&gt; option. Without it, Skopeo tries to copy the signatures to the destination registry server, and this is only supported on the OpenShift internal registry. Signatures of the source images are still validated during the copy operation.&lt;/p&gt; &lt;p&gt;Next, login to your account at Quay.io and use the &lt;code&gt;skopeo copy&lt;/code&gt; command to create your mirror of the UBI container image:&lt;/p&gt; &lt;pre&gt;$ podman login -u flozanorht quay.io Password: Login Succeeded! $ skopeo copy --remove-signatures --sign-by flozano@redhat.com \ docker://registry.access.redhat.com/ubi8/ubi:8.0-199 \ docker://quay.io/flozanorht/ubi:8.0-199&lt;/pre&gt; &lt;p&gt;Now, as another way to verify that the container runtime is actually checking container image signatures, use the &lt;code&gt;--log-level debug&lt;/code&gt; option from &lt;code&gt;podman&lt;/code&gt; to start a container using your copy of the UBI image:&lt;/p&gt; &lt;pre&gt;$ sudo podman --log-level debug run --rm --name test \ quay.io/flozanorht/ubi:8.0-199 date Trying to pull quay.io/flozanorht/ubi:8.0-199...DEBU[0000] Using registries.d directory /etc/containers/registries.d for sigstore configuration DEBU[0000]  Using "docker" namespace quay.io/flozanorht/ubi DEBU[0000]   Using file:///var/lib/atomic/sigstore/ ... DEBU[0001] GET https://quay.io/v2/flozanorht/ubi/manifests/8.0-199 DEBU[0002] IsRunningImageAllowed for image docker:quay.io/flozanorht/ubi:8.0-199 DEBU[0002]  Using transport "docker" specific policy section quay.io/flozanorht/ubi DEBU[0002] Reading /var/lib/atomic/sigstore//flozanorht/ubi@sha256=c318fd9549dda67f3a1b3aa19b55b26b9dd42f597c3f2ee4181f0d9de16226de/signature-1 DEBU[0002] Reading /var/lib/atomic/sigstore//flozanorht/ubi@sha256=c318fd9549dda67f3a1b3aa19b55b26b9dd42f597c3f2ee4181f0d9de16226de/signature-2 DEBU[0002]  Requirement 0: allowed                     DEBU[0002] Overall: allowed                            Getting image source signatures ... DEBU[0002] Started container 5148003a4eebc4ac256add74f127b4993217909189f6571b15fc77e883fbcd4f Wed Oct  9 03:41:38 UTC 2019 DEBU[0002] Checking container 5148003a4eebc4ac256add74f127b4993217909189f6571b15fc77e883fbcd4f status… DEBU[0002] Cleaning up container 5148003a4eebc4ac256add74f127b4993217909189f6571b15fc77e883fbcd4f&lt;/pre&gt; &lt;p&gt;It is hard to find the output of the &lt;code&gt;podman&lt;/code&gt; command with all the logging around it. The debug messages could be more clear that the signature was valid. However, you can see that it reads the &lt;code&gt;quay.yaml&lt;/code&gt; and &lt;code&gt;policy.json&lt;/code&gt; configuration files and reads the signatures from &lt;code&gt;/var/lib/atomic/sigstore/&lt;/code&gt; before stating &lt;code&gt;Requirement 0: allowed&lt;/code&gt;.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;In this article, I showed how anyone can play with container image signatures without a complicated setup. Moving into a production scenario, you would do two things:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Add the Red Hat terms-based registry at registry.redhat.io to your configuration.&lt;/li&gt; &lt;li&gt;Work on a script that lists all tags of the images you want to mirror and then copy each of them. Skopeo is smart enough to not copy again images and layers you already have on your private registry.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;RHEL7 users can manage the signature-related files in &lt;code&gt;/etc/containers&lt;/code&gt; using the &lt;code&gt;atomic&lt;/code&gt; command. RHEL8 can do the same using the podman image trust command (not to be confused with the &lt;code&gt;podman images&lt;/code&gt; command). See references 4, 5, and 6 for more information.&lt;/p&gt; &lt;p&gt;If you are new to the Linux container tools (Podman, Buildah, and Skopeo), see references 7 and 8 below.&lt;/p&gt; &lt;h2&gt;References&lt;/h2&gt; &lt;p&gt;1. &lt;a href="https://access.redhat.com/security/team/key"&gt;Product Signing Keys&lt;/a&gt; on the Red Hat Customer Portal&lt;/p&gt; &lt;p&gt;2. &lt;a href="https://www.redhat.com/en/blog/using-rootless-containers-tech-preview-rhel-80"&gt;Using the rootless containers Tech Preview in RHEL 8.0&lt;/a&gt;&lt;/p&gt; &lt;p&gt;3. &lt;a href="https://help.github.com/en/articles/generating-a-new-gpg-key"&gt;Generating a new GPG key&lt;/a&gt;&lt;/p&gt; &lt;p&gt;4. &lt;a href="https://www.redhat.com/en/blog/signed-images-red-hat-container-catalog"&gt;Signed Images from the Red Hat Container Catalog&lt;/a&gt;&lt;/p&gt; &lt;p&gt;5. &lt;a href="https://access.redhat.com/articles/3116561"&gt;Verifying image signing for Red Hat Container Registry&lt;/a&gt;&lt;/p&gt; &lt;p&gt;6. &lt;a href="https://github.com/containers/image/tree/master/docs"&gt;https://github.com/containers/image/tree/master/docs&lt;/a&gt;&lt;/p&gt; &lt;p&gt;7. &lt;a href="https://servicesblog.redhat.com/2019/10/09/say-hello-to-buildah-podman-and-skopeo/"&gt;Say “Hello” to Buildah, Podman, and Skopeo&lt;/a&gt;&lt;/p&gt; &lt;p&gt;8. &lt;a href="https://developers.redhat.com/blog/2019/02/21/podman-and-buildah-for-docker-users/"&gt;Podman and Buildah for Docker users&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F29%2Fverifying-signatures-of-red-hat-container-images%2F&amp;#38;linkname=Verifying%20signatures%20of%20Red%20Hat%20container%20images" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F29%2Fverifying-signatures-of-red-hat-container-images%2F&amp;#38;linkname=Verifying%20signatures%20of%20Red%20Hat%20container%20images" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F29%2Fverifying-signatures-of-red-hat-container-images%2F&amp;#38;linkname=Verifying%20signatures%20of%20Red%20Hat%20container%20images" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F29%2Fverifying-signatures-of-red-hat-container-images%2F&amp;#38;linkname=Verifying%20signatures%20of%20Red%20Hat%20container%20images" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F29%2Fverifying-signatures-of-red-hat-container-images%2F&amp;#38;linkname=Verifying%20signatures%20of%20Red%20Hat%20container%20images" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F29%2Fverifying-signatures-of-red-hat-container-images%2F&amp;#38;linkname=Verifying%20signatures%20of%20Red%20Hat%20container%20images" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F29%2Fverifying-signatures-of-red-hat-container-images%2F&amp;#38;linkname=Verifying%20signatures%20of%20Red%20Hat%20container%20images" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F29%2Fverifying-signatures-of-red-hat-container-images%2F&amp;#038;title=Verifying%20signatures%20of%20Red%20Hat%20container%20images" data-a2a-url="https://developers.redhat.com/blog/2019/10/29/verifying-signatures-of-red-hat-container-images/" data-a2a-title="Verifying signatures of Red Hat container images"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/10/29/verifying-signatures-of-red-hat-container-images/"&gt;Verifying signatures of Red Hat container images&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/5FkPUU4DLWc" height="1" width="1" alt=""/&gt;</content><summary>Security-conscious organizations are accustomed to using digital signatures to validate application content from the Internet. A common example is RPM package signing. Red Hat Enterprise Linux (RHEL) validates signatures of RPM packages by default. In the container world, a similar paradigm should be adhered to. In fact, all container images from Red Hat have been digitally signed and have been fo...</summary><dc:creator>Fernando Lozano</dc:creator><dc:date>2019-10-29T06:59:46Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2019/10/29/verifying-signatures-of-red-hat-container-images/</feedburner:origLink></entry><entry><title>Microbenchmarks for AI applications using Red Hat OpenShift on PSI in project Thoth</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/WfnAImyJSxw/" /><category term="artificial intelligence" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="machine learning" scheme="searchisko:content:tags" /><category term="openshift" scheme="searchisko:content:tags" /><category term="Red Hat OpenShift Container Platform" scheme="searchisko:content:tags" /><author><name>Francesco Murdaca</name></author><id>searchisko:content:id:jbossorg_blog-microbenchmarks_for_ai_applications_using_red_hat_openshift_on_psi_in_project_thoth</id><updated>2019-10-28T07:00:56Z</updated><published>2019-10-28T07:00:56Z</published><content type="html">&lt;p&gt;&lt;a href="https://github.com/thoth-station" target="_blank" rel="noopener noreferrer"&gt;Project Thoth&lt;/a&gt; is an artificial intelligence (AI) R&amp;#38;D Red Hat research project as part of the Office of the CTO and the &lt;a href="https://github.com/AICoE"&gt;AI Center of Excellence (CoE)&lt;/a&gt;. This project aims to build a knowledge graph and a recommendation system for application stacks based on the collected knowledge, such as machine learning (ML) applications that rely on popular open source ML frameworks and libraries (TensorFlow, PyTorch, MXNet, etc.). In this article, we examine the potential of project Thoth&amp;#8217;s infrastructure running in &lt;a href="https://developers.redhat.com/openshift/"&gt;Red Hat Openshift&lt;/a&gt; and explore how it can collect performance observations.&lt;/p&gt; &lt;p&gt;Several types of observations are gathered from various domains (like build time, run time and performance, and application binary interfaces (ABI)). These observations are collected through the &lt;a href="https://github.com/thoth-station/core" target="_blank" rel="noopener noreferrer"&gt;Thoth system&lt;/a&gt; and enrich the knowledge graph automatically. The knowledge graph is then used to learn from the observations. Project &lt;a href="https://github.com/thoth-station/core" target="_blank" rel="noopener noreferrer"&gt;Thoth architecture&lt;/a&gt; requires multi-namespace deployment in an OpenShift environment, which is run on PnT DevOps Shared Infrastructure (PSI), a shared multi-tenant OpenShift cluster.&lt;span id="more-639947"&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;Thoth recommendations are provided through a &lt;a href="https://github.com/thoth-station/thamos"&gt;Thamos CLI&lt;/a&gt;, which is a tool and library for communicating with Thoth back end. The recommendation engine for project Thoth is called &lt;a href="https://github.com/thoth-station/adviser" target="_blank" rel="noopener noreferrer"&gt;Adviser&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;There are the following main goals of &lt;a href="https://github.com/thoth-station/adviser"&gt;Adviser&lt;/a&gt; (as of now):&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Provide a tool that can compute recommendations in project &lt;a href="https://thoth-station.ninja/" rel="nofollow"&gt;Thoth&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;&lt;a href="https://github.com/thoth-station/adviser/blob/master/docs/source/provenance_checks.rst"&gt;Check provenance&lt;/a&gt; of installed packages (which package source indexes are used &amp;#8211; this is not guaranteed by pip nor Pipenv).&lt;/li&gt; &lt;li&gt;A tool called &lt;a href="https://github.com/thoth-station/adviser/blob/master/docs/source/dependency_monkey.rst"&gt;Dependency Monkey&lt;/a&gt;, which generates all the possible software stacks for a project respecting dependency resolution.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;The recommendations for AI software stacks require the collection of performance observations across huge number of combinations of libraries in software stacks. To capture these performance differences, Thoth relies on microbenchmarks created specifically for Thoth requirements, called &lt;a href="https://github.com/thoth-station/performance"&gt;performance indicators (PIs)&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;To define these new type of benchmarks, we analyzed ML benchmarks (e.g., &lt;a href="https://mlperf.org/"&gt;MLPerf&lt;/a&gt;, &lt;a href="https://github.com/baidu-research/DeepBench"&gt;Baidu DeepBench&lt;/a&gt;, &lt;a href="https://dawn.cs.stanford.edu/benchmark/"&gt;Stanford DAWN Deep Learning Benchmark (DAWNBench)&lt;/a&gt;, &lt;a href="https://developer.hpe.com/platform/hpe-deep-learning-cookbook/home"&gt;The Deep Learning Cookbook&lt;/a&gt;), and we classified them into two categories:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;High-Level Test, also called macro-benchmarks, performed at the application level, so a real application, considering different datasets, models, hyperparameters tuning, OS libraries, hardware, etc., therefore considering the entire ML workload (e.g., ML Perf).&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;img class=" aligncenter wp-image-643737 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/10/High-Level-Test-on-Machine-1024x392.jpg" src="https://developers.redhat.com/blog/wp-content/uploads/2019/10/High-Level-Test-on-Machine-1024x392.jpg" alt="" width="640" height="245" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/10/High-Level-Test-on-Machine-1024x392.jpg 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/10/High-Level-Test-on-Machine-300x115.jpg 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/10/High-Level-Test-on-Machine-768x294.jpg 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/10/High-Level-Test-on-Machine.jpg 1241w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/p&gt; &lt;p style="text-align: center;"&gt;&lt;em&gt;Figure 1: High-level test schema.&lt;/em&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Low-Level Test, also called microbenchmarks, focused on basic operations that constitute the backbone of the ML algorithms. (e.g., DeepBench).&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;img class=" aligncenter wp-image-643747 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/10/Low-Level-Test-on-Machine-1024x401.jpg" src="https://developers.redhat.com/blog/wp-content/uploads/2019/10/Low-Level-Test-on-Machine-1024x401.jpg" alt="" width="640" height="251" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/10/Low-Level-Test-on-Machine-1024x401.jpg 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/10/Low-Level-Test-on-Machine-300x117.jpg 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/10/Low-Level-Test-on-Machine-768x300.jpg 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/10/Low-Level-Test-on-Machine.jpg 1240w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/p&gt; &lt;p style="text-align: center;"&gt;&lt;em&gt;Figure 2: Low-level test schema.&lt;/em&gt;&lt;/p&gt; &lt;p&gt;We also analyzed ML applications and their algorithms, and through their decomposition in basic components, we arrived at the definition of the PI. The table below describes the Thoth PI with respect to existing ML benchmarks. We can immediately see that Thoth is uniquely focused on the software stacks; therefore, it&amp;#8217;s not overlapping with other existing efforts. The entire analysis was important to guarantee the requirements for Thoth: low evaluation time, software stack focused, ML framework focused, for training and inference.&lt;/p&gt; &lt;table class=" aligncenter" style="height: 476px;" width="910"&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;/td&gt; &lt;td&gt;&lt;b&gt;Benchmark &lt;/b&gt;&lt;/p&gt; &lt;p&gt;&lt;b&gt;(High-Level Test)&lt;/b&gt;&lt;/td&gt; &lt;td&gt;&lt;b&gt;Thoth PI&lt;/b&gt;&lt;/td&gt; &lt;td&gt;&lt;b&gt;Microbenchmark&lt;/b&gt;&lt;/p&gt; &lt;p&gt;&lt;b&gt;(Low-Level Test)&lt;/b&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;b&gt;Goal&lt;/b&gt;&lt;/td&gt; &lt;td&gt;Measure system performance for both training and inference from mobile devices to cloud services.&lt;/td&gt; &lt;td&gt;Evaluate Performance Indicators that can be used to recommend AI software stacks.&lt;/td&gt; &lt;td&gt;Benchmark operations that are important to deep learning on different hardware platforms.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;b&gt;Metrics&lt;/b&gt;&lt;/td&gt; &lt;td&gt; &lt;ul&gt; &lt;li&gt;Time&lt;/li&gt; &lt;li&gt;FLOPS&lt;/li&gt; &lt;li&gt;Cost&lt;/li&gt; &lt;/ul&gt; &lt;/td&gt; &lt;td&gt; &lt;ul&gt; &lt;li&gt;Time&lt;/li&gt; &lt;li&gt;FLOPS&lt;/li&gt; &lt;/ul&gt; &lt;/td&gt; &lt;td&gt; &lt;ul&gt; &lt;li&gt;Time&lt;/li&gt; &lt;li&gt;FLOPS&lt;/li&gt; &lt;/ul&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;b&gt;Time requested for benchmarking&lt;/b&gt;&lt;/td&gt; &lt;td&gt;~hours, days&lt;/td&gt; &lt;td&gt;~minutes, (hours?)&lt;/td&gt; &lt;td&gt;~seconds, minutes&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;b&gt;Using ML Frameworks&lt;/b&gt;&lt;/td&gt; &lt;td&gt;Yes&lt;/td&gt; &lt;td&gt;Yes&lt;/td&gt; &lt;td&gt;No&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;b&gt;Phases of ML workflow&lt;/b&gt;&lt;/td&gt; &lt;td&gt;Training/Inference&lt;/td&gt; &lt;td&gt;Training/Inference&lt;/td&gt; &lt;td&gt;Training/Inference&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;p&gt;We can now define PIs as: &lt;em&gt;scripts run to collect performance observations regarding AI software stacks for both training and inference minimizing the time of evaluation.&lt;/em&gt;&lt;/p&gt; &lt;p&gt;PIs are defined for each ML framework from the analysis of the ML applications and algorithms. Each PI has specific parameters that need to be tuned and tested to identify constraints that allow the minimization of errors due to the shared infrastructure on which they run.&lt;/p&gt; &lt;p&gt;The next sections show how PIs are evaluated using &lt;a href="http://developers.redhat.com/openshift/"&gt;Red Hat OpenShift&lt;/a&gt; and the automated process that is triggered once a new version of an ML library is released. Moreover, they will show the preliminary results obtained in order to guarantee transparency, reliability, and accuracy to Thoth users. These results will show that we are able to identify differences in software stack performance, and therefore that we can use these observations to recommend software stacks with higher performance.&lt;/p&gt; &lt;h2&gt;How do we run these benchmarks for AI applications?&lt;/h2&gt; &lt;p&gt;The performance of a software stack depends on many parameters. It is necessary to consider the entire software stack&amp;#8217;s layers in order to understand their behavior and the different factors affecting their performance.&lt;/p&gt; &lt;p&gt;&lt;a href="https://github.com/thoth-station/amun-api"&gt;Amun&lt;/a&gt; is a service that executes the application stack in the requested environment, using the list of packages that should be installed as well as the hardware that is requested to run the application. Its primary purpose is to act as an execution engine for Thoth, where applications are built and tested (applications are automatically generated given the software&amp;#8217;s requirements).&lt;/p&gt; &lt;p&gt;The inputs are given through a JSON file that allows the selection of all components present in the layers of a software stack, such as the:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Base image (e.g., &lt;code&gt;rhel8&lt;/code&gt;, &lt;code&gt;ubi8&lt;/code&gt;, &lt;code&gt;thoth-ubi8-python36&lt;/code&gt;)&lt;/li&gt; &lt;li&gt;List of RPMs or Debian packages&lt;/li&gt; &lt;li&gt;Pinned down software stack (&lt;code&gt;Pipfile&lt;/code&gt; and &lt;code&gt;Pipfile.lock&lt;/code&gt;)&lt;/li&gt; &lt;li&gt;Hardware requirements (e.g., CPU only, GPU)&lt;/li&gt; &lt;li&gt;PIs and parameters&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Amun can be run directly through the CLI or through &lt;a href="https://github.com/thoth-station/adviser/blob/master/docs/source/dependency_monkey.rst" target="_blank" rel="noopener noreferrer"&gt;Dependency Monkey&lt;/a&gt;, which generates software stacks that are subsequently validated and scored using the Amun service with a specific PI. In this way, we can learn the differences in performance from different software stacks and hardware.&lt;/p&gt; &lt;p&gt;Every PI has specific input parameters, but each of them collects different types of data, such as hardware information, resource usage, etc.&lt;/p&gt; &lt;p&gt;There are two results specifically focused on performance. One result is FLOPS (floating-point operations per second) or GigaFlops (or GFLOPS), which is a billion FLOPS. The other result is the time spent to perform a specific operation, measured in seconds or milliseconds. This second result is also called &lt;em&gt;elapsed time.&lt;/em&gt;&lt;/p&gt; &lt;p&gt;We can extend the results depending on what we want to capture from a PI run.&lt;/p&gt; &lt;h2&gt;Where do we run microbenchmarks for AI applications?&lt;/h2&gt; &lt;p&gt;The ML application is influenced by all layers of the software stack, so evaluating performance requires the use of PIs that can approximate the application&amp;#8217;s behavior with high confidence. At the same time, the ML application requires a platform for testing that provides all of the information required to evaluate and analyze the results in order to guarantee the results&amp;#8217; reliability, transparency, and accuracy.&lt;/p&gt; &lt;p&gt;The need for scalability, automation, reliability, and monitorability due to the huge number of software stacks to be analyzed—and consequently a high number of observations to be collected—is fulfilled by the use of OpenShift running on PSI.&lt;/p&gt; &lt;div id="attachment_640227" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-640227" class=" aligncenter wp-image-640227 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/10/img_5da57d453f85e-1024x534.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/10/img_5da57d453f85e-1024x534.png" alt="Thoth performance" width="640" height="334" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/10/img_5da57d453f85e-1024x534.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/10/img_5da57d453f85e-300x156.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/10/img_5da57d453f85e-768x400.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/10/img_5da57d453f85e.png 1350w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-640227" class="wp-caption-text"&gt;&lt;em&gt;Figure 3: Thoth performance indicator test environment.&lt;/em&gt;&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Figure 3 shows the test environment we selected to run our Thoth PIs. This figure highlights the inputs that can be provided (as shown in the previous section) to evaluate software stack performance in all possible situations:&lt;/p&gt; &lt;p id="halxVBX"&gt;If we look at Figure 4, it is possible to identify the part of the Thoth &lt;a href="https://raw.githubusercontent.com/thoth-station/core/master/doc/architecture.png" target="_blank" rel="noopener noreferrer"&gt;core architecture&lt;/a&gt; that focuses on running the PIs (called &lt;em&gt;inspection runs&lt;/em&gt;):&lt;/p&gt; &lt;div id="attachment_640247" style="width: 610px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-640247" class=" aligncenter wp-image-640247 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/10/img_5da58557e4c7e.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/10/img_5da58557e4c7e.png" alt="Thoth core architecture" width="600" height="605" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/10/img_5da58557e4c7e.png 662w, https://developers.redhat.com/blog/wp-content/uploads/2019/10/img_5da58557e4c7e-150x150.png 150w, https://developers.redhat.com/blog/wp-content/uploads/2019/10/img_5da58557e4c7e-297x300.png 297w" sizes="(max-width: 600px) 100vw, 600px" /&gt;&lt;p id="caption-attachment-640247" class="wp-caption-text"&gt;&lt;em&gt;Figure 4: Thoth core architecture.&lt;/em&gt;&lt;/p&gt;&lt;/div&gt; &lt;p&gt;The inspections run can be submitted directly through the Amun API or through Dependency Monkey, which generates a combination of software stacks to be inspected. Two to three namespaces are involved: Amun runs in the Amun API namespace and generates inspection builds and inspection jobs in the Amun Inspection namespace. Once the jobs are finished, the graph sync job stores the result documents in Ceph and syncs them in Thoth Knowledge Base.&lt;/p&gt; &lt;h2&gt;When do we run microbenchmarks for AI applications?&lt;/h2&gt; &lt;p&gt;Many services are automated inside Thoth. Bots supporting the developer team rely on OpenShift monitorability features, thanks to Prometheus Alerts and Grafana. All result quality analysis is automated by running Thoth &lt;a href="https://github.com/thoth-station/notebooks/tree/master/notebooks/templates"&gt;template notebooks&lt;/a&gt; triggered automatically inside jobs. In this way, we can reduce the workload and focus on the definition of test constraints in order to achieve the best accuracy. The approach we use is data-driven, which helps the team internally and facilitates the improvements to be made to guarantee reliability and quality to external Thoth users.&lt;/p&gt; &lt;p&gt;Let&amp;#8217;s assume a new release of TensorFlow is issued on &lt;a href="https://pypi.org/" target="_blank" rel="noopener noreferrer"&gt;PyPI index&lt;/a&gt;. The typical workflow triggered inside Thoth is shown in Figure 5:&lt;/p&gt; &lt;div id="attachment_640287" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-640287" class=" aligncenter wp-image-640287 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/10/img_5da58bd0a4ccc-1024x397.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/10/img_5da58bd0a4ccc-1024x397.png" alt="Typical Thoth workflow" width="640" height="248" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/10/img_5da58bd0a4ccc-1024x397.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/10/img_5da58bd0a4ccc-300x116.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/10/img_5da58bd0a4ccc-768x298.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-640287" class="wp-caption-text"&gt;&lt;em&gt;Figure 5: A typical Thoth workflow when a new TensorFlow is released.&lt;/em&gt;&lt;/p&gt;&lt;/div&gt; &lt;p&gt;This workflow breaks down as follows:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;A new version of TensorFlow is released by Google on PyPI.&lt;/li&gt; &lt;li&gt;&lt;a href="https://github.com/thoth-station/package-releases-job" target="_blank" rel="noopener noreferrer"&gt;Package Releases Job&lt;/a&gt;: &lt;ol&gt; &lt;li&gt;Identifies the new TensorFlow release.&lt;/li&gt; &lt;li&gt;Syncs the new package in Thoth database.&lt;/li&gt; &lt;li&gt;Re-triggers the &lt;a href="https://github.com/thoth-station/tensorflow-build-s2i" target="_blank" rel="noopener noreferrer"&gt;TensorFlow Build&lt;/a&gt; pipeline.&lt;/li&gt; &lt;/ol&gt; &lt;/li&gt; &lt;li&gt;&lt;a href="https://github.com/thoth-station/graph-refresh-job" target="_blank" rel="noopener noreferrer"&gt;Graph Refresh Job&lt;/a&gt;: &lt;ol&gt; &lt;li&gt;Identifies the new Package and requests job scheduling.&lt;/li&gt; &lt;li&gt;Schedules a &lt;a href="https://github.com/thoth-station/solver" target="_blank" rel="noopener noreferrer"&gt;Solver Job&lt;/a&gt; through &lt;code&gt;operator-workload&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;Schedules a &lt;a href="https://github.com/thoth-station/analyzer" target="_blank" rel="noopener noreferrer"&gt;Package Analyzer Job&lt;/a&gt; through &lt;code&gt;operator-workload&lt;/code&gt;.&lt;/li&gt; &lt;/ol&gt; &lt;/li&gt; &lt;li&gt;Two things happen at once. First, the results are: &lt;ol&gt; &lt;li&gt;Created from Jobs.&lt;/li&gt; &lt;li&gt;Stored in Thoth Knowledge Graph through &lt;code&gt;&lt;a href="https://github.com/thoth-station/graph-sync-job" target="_blank" rel="noopener noreferrer"&gt;graph-sync-job&lt;/a&gt;&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;Stored in Ceph through &lt;code&gt;&lt;a href="https://github.com/thoth-station/graph-sync-job" target="_blank" rel="noopener noreferrer"&gt;graph-sync-job&lt;/a&gt;&lt;/code&gt;.&lt;/li&gt; &lt;/ol&gt; &lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Meanwhile, &lt;code&gt;tensorflow-wheels-build-jobs&lt;/code&gt; are finished and new optimized versions of TensorFlow are released on &lt;a href="https://tensorflow.pypi.thoth-station.ninja/"&gt;AICoE index&lt;/a&gt; that goes through all same points above.&lt;/p&gt; &lt;ol start="5"&gt; &lt;li&gt;Prometheus scrapes metrics from Pushegateway and &lt;code&gt;metrics-exporter&lt;/code&gt; and provides insights into what is happening to the Thoth team.&lt;/li&gt; &lt;li&gt;Prometheus triggers alerts according to the results defined by the Thoth team.&lt;/li&gt; &lt;li&gt;&lt;a href="https://github.com/AICoE/sesheta" target="_blank" rel="noopener noreferrer"&gt;Sesheta&lt;/a&gt;, Thoth’s Bot team member, sends feedback and status on the Thoth DevOps chat. According to the logic and rules, it can decide to trigger analysis of inspections to evaluate PI through &lt;a href="https://github.com/thoth-station/adviser/blob/master/docs/source/dependency_monkey.rst" target="_blank" rel="noopener noreferrer"&gt;Dependency Monkey&lt;/a&gt; or &lt;a href="https://github.com/thoth-station/amun-api" target="_blank" rel="noopener noreferrer"&gt;Amun&lt;/a&gt; directly.&lt;/li&gt; &lt;li&gt;Dependency Monkey generates software stacks and starts to schedule Inspections through the Amun API, or Amun is triggered directly from Sesheta and inspections are sent to the workload operator.&lt;/li&gt; &lt;li&gt;All results are stored in the Thoth Knowledge Graph and Ceph.&lt;/li&gt; &lt;li&gt;Quality analysis of inspection jobs is triggered when each inspection batch is finished, using Thoth template notebooks, and results are provided to the team and outside the team.&lt;/li&gt; &lt;/ol&gt; &lt;h2&gt;Tests and results&lt;/h2&gt; &lt;p&gt;These tests are focused on &lt;a href="https://github.com/thoth-station/performance/blob/master/tensorflow/matmul.py" target="_blank" rel="noopener noreferrer"&gt;matmul&lt;/a&gt; microbenchmarks for TensorFlow. The inputs parameters for this PI are:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Matrix size&lt;/li&gt; &lt;li&gt;Data type&lt;/li&gt; &lt;li&gt;Number of operation repetitions&lt;/li&gt; &lt;/ul&gt; &lt;h3&gt;Test 1&lt;/h3&gt; &lt;p&gt;Test 1 aims to identify the number of repetitions that reduce the error on the rate, fixing type of data and matrix size. The input parameters are:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;TensorFlow 1.13 from PyPI&lt;/li&gt; &lt;li&gt;Fedora base image&lt;/li&gt; &lt;li&gt;matmul (TensorFlow, matrix size=512, {repetitions}, data_type=float32)&lt;/li&gt; &lt;li&gt;300 inspections&lt;/li&gt; &lt;li&gt;CPU-only&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;The results for Test 1 are shown in Figures 6 through 9:&lt;/p&gt; &lt;div id="attachment_640417" style="width: 458px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-640417" class=" aligncenter wp-image-640417 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/10/img_5da59a12c3c6a.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/10/img_5da59a12c3c6a-300x193.png" alt="Test 1's plots rates per batch." width="448" height="288" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/10/img_5da59a12c3c6a-300x193.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/10/img_5da59a12c3c6a.png 700w" sizes="(max-width: 448px) 100vw, 448px" /&gt;&lt;p id="caption-attachment-640417" class="wp-caption-text"&gt;&lt;em&gt;Figure 6: Test 1&amp;#8217;s box plots rates per batch.&lt;/em&gt;&lt;/p&gt;&lt;/div&gt; &lt;div id="attachment_640447" style="width: 459px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-640447" class=" aligncenter wp-image-640447 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/10/img_5da59bd1ed491.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/10/img_5da59bd1ed491-300x251.png" alt="Test 1's violin plot rate per batch." width="449" height="375" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/10/img_5da59bd1ed491-300x251.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/10/img_5da59bd1ed491.png 712w" sizes="(max-width: 449px) 100vw, 449px" /&gt;&lt;p id="caption-attachment-640447" class="wp-caption-text"&gt;&lt;em&gt;Figure 7: Test 1&amp;#8217;s violin plot rate per batch.&lt;/em&gt;&lt;/p&gt;&lt;/div&gt; &lt;div id="attachment_640457" style="width: 459px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-640457" class=" aligncenter wp-image-640457 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/10/img_5da59c3664ce0.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/10/img_5da59c3664ce0-300x250.png" alt="Test 1's statistics plot of std for rate of different batch." width="449" height="375" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/10/img_5da59c3664ce0-300x250.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/10/img_5da59c3664ce0.png 713w" sizes="(max-width: 449px) 100vw, 449px" /&gt;&lt;p id="caption-attachment-640457" class="wp-caption-text"&gt;&lt;em&gt;Figure 8: Test 1&amp;#8217;s statistics plot of std for &lt;/em&gt;rate&lt;em&gt; of &lt;/em&gt;different&lt;em&gt; batch.&lt;/em&gt;&lt;/p&gt;&lt;/div&gt; &lt;div id="attachment_640467" style="width: 458px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-640467" class=" aligncenter wp-image-640467 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/10/img_5da59c4c7cd39.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/10/img_5da59c4c7cd39-300x247.png" alt="Test 1's interpolated statistics for rate of different batch." width="448" height="369" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/10/img_5da59c4c7cd39-300x247.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/10/img_5da59c4c7cd39.png 723w" sizes="(max-width: 448px) 100vw, 448px" /&gt;&lt;p id="caption-attachment-640467" class="wp-caption-text"&gt;&lt;em&gt;Figure 9: Test 1&amp;#8217;s interpolated statistics for &lt;/em&gt;rate&lt;em&gt; of &lt;/em&gt;different&lt;em&gt; batch.&lt;/em&gt;&lt;/p&gt;&lt;/div&gt; &lt;p&gt;According to the results obtained for matrix 512, we can investigate into more detail for two specific batches where the variation on the results is lower, as shown in Figures 10 and 11:&lt;/p&gt; &lt;div id="attachment_640487" style="width: 459px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-640487" class=" aligncenter wp-image-640487 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/10/img_5da59c8d8ae9b.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/10/img_5da59c8d8ae9b.png" alt="Test 1's box plots rate per specified batches." width="449" height="368" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/10/img_5da59c8d8ae9b.png 710w, https://developers.redhat.com/blog/wp-content/uploads/2019/10/img_5da59c8d8ae9b-300x246.png 300w" sizes="(max-width: 449px) 100vw, 449px" /&gt;&lt;p id="caption-attachment-640487" class="wp-caption-text"&gt;&lt;em&gt;Figure 10: Test 1&amp;#8217;s box plots rate per specified batches.&lt;/em&gt;&lt;/p&gt;&lt;/div&gt; &lt;div id="attachment_640497" style="width: 458px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-640497" class=" aligncenter wp-image-640497 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/10/img_5da59c9572179.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/10/img_5da59c9572179.png" alt="Test 1's violin plot rate per specified batches." width="448" height="367" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/10/img_5da59c9572179.png 710w, https://developers.redhat.com/blog/wp-content/uploads/2019/10/img_5da59c9572179-300x246.png 300w" sizes="(max-width: 448px) 100vw, 448px" /&gt;&lt;p id="caption-attachment-640497" class="wp-caption-text"&gt;&lt;em&gt;Figure 11: Test 1&amp;#8217;s violin plot rate per specified batches.&lt;/em&gt;&lt;/p&gt;&lt;/div&gt; &lt;p&gt;From these results, we decided to initially use 2,000 repetitions to run matmul PIs, as matmul has the lowest variation on the rate (which is fundamental for scoring packages, and therefore fundamental for the quality of the recommendations given by Thoth).&lt;/p&gt; &lt;h3&gt;Test 2&lt;/h3&gt; &lt;p&gt;Test 2 aims to identify the quality of the results, fixing the number of repetitions with the best solution identified during Test 1, but changing the matrix size. In this test, we reduce the number of inspections per batch to 100 (in Test 1, we ran 300 inspections per inspection batch). In this test, we also have a newer version of TensorFlow and the base image. This test&amp;#8217;s input parameters include:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;TensorFlow 1.14.0 from PyPI&lt;/li&gt; &lt;li&gt;&lt;code&gt;s2i-Thoth-ubi8-python36&lt;/code&gt; base image&lt;/li&gt; &lt;li&gt;matmul (TensorFlow, {matrix size}, repetitions=2k, data_type=float32)&lt;/li&gt; &lt;li&gt;100 inspections&lt;/li&gt; &lt;li&gt;CPU-only&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;The matrix size changed for 64, 128, 256, 512, 1024, 2048, 4096.&lt;/p&gt; &lt;p&gt;The results for Test 2 are shown in Figures 12 and 13:&lt;/p&gt; &lt;div id="attachment_640517" style="width: 479px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-640517" class=" aligncenter wp-image-640517 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/10/img_5da59d656faf8.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/10/img_5da59d656faf8.png" alt="Test 2's interpolated statistics for elapsed time of different batch." width="469" height="385" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/10/img_5da59d656faf8.png 742w, https://developers.redhat.com/blog/wp-content/uploads/2019/10/img_5da59d656faf8-300x246.png 300w" sizes="(max-width: 469px) 100vw, 469px" /&gt;&lt;p id="caption-attachment-640517" class="wp-caption-text"&gt;&lt;em&gt;Figure 12: Test 2&amp;#8217;s interpolated statistics for &lt;/em&gt;elapsed&lt;em&gt; time of different batch.&lt;/em&gt;&lt;/p&gt;&lt;/div&gt; &lt;div id="attachment_640527" style="width: 494px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-640527" class=" aligncenter wp-image-640527 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/10/img_5da59d7145b8c.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/10/img_5da59d7145b8c.png" alt="Test 2's interpolated statistics for rate of different batch." width="484" height="402" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/10/img_5da59d7145b8c.png 733w, https://developers.redhat.com/blog/wp-content/uploads/2019/10/img_5da59d7145b8c-300x249.png 300w" sizes="(max-width: 484px) 100vw, 484px" /&gt;&lt;p id="caption-attachment-640527" class="wp-caption-text"&gt;&lt;em&gt;Figure 13: Test 2&amp;#8217;s interpolated statistics for &lt;/em&gt;rate&lt;em&gt; of &lt;/em&gt;different&lt;em&gt; batch.&lt;/em&gt;&lt;/p&gt;&lt;/div&gt; &lt;p&gt;We can see from the results that the underlying hardware uses optimization when the matrix size becomes high, and at the same time we can see an increase in variations of the results on the rate, but not on the elapsed time. Thoth is able to catch these behaviors and provide recommendations to users so that they can run AI applications in the best conditions.&lt;/p&gt; &lt;h2&gt;Performance changes identified&lt;/h2&gt; &lt;p&gt;Let’s focus on two specific inspection batches from the two tests to show more insights and performance observations that Thoth captures.&lt;/p&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Test 1&lt;/td&gt; &lt;td&gt;Test 2&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Input Parameters:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;TensorFlow 1.13.0 from PyPI&lt;/li&gt; &lt;li&gt;Fedora base image&lt;/li&gt; &lt;li&gt;matmul (TensorFlow, matrix size=512, repetitions=2k, data_type=float32)&lt;/li&gt; &lt;li&gt;300 inspections&lt;/li&gt; &lt;li&gt;CPU-only&lt;/li&gt; &lt;/ul&gt; &lt;/td&gt; &lt;td&gt;Input Parameters:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;TensorFlow 1.14.0 from PyPI&lt;/li&gt; &lt;li&gt;&lt;code&gt;s2i-Thoth-ubi8-python36&lt;/code&gt; base image&lt;/li&gt; &lt;li&gt;matmul (TensorFlow, matrix size=512, repetitions=2k, data_type=float32)&lt;/li&gt; &lt;li&gt;100 inspections&lt;/li&gt; &lt;li&gt;CPU-only&lt;/li&gt; &lt;/ul&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;p&gt;Results are compared for the Rate [GFLOPS] in Figure 14:&lt;/p&gt; &lt;div id="attachment_640537" style="width: 477px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-640537" class=" aligncenter wp-image-640537 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/10/img_5da59e1c7b84d.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/10/img_5da59e1c7b84d.png" alt="Interpolated statistics for rate of different batch (GFLOPS)." width="467" height="383" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/10/img_5da59e1c7b84d.png 710w, https://developers.redhat.com/blog/wp-content/uploads/2019/10/img_5da59e1c7b84d-300x246.png 300w" sizes="(max-width: 467px) 100vw, 467px" /&gt;&lt;p id="caption-attachment-640537" class="wp-caption-text"&gt;&lt;em&gt;Figure 14: Interpolated statistics for rate of different batch (GFLOPS).&lt;/em&gt;&lt;/p&gt;&lt;/div&gt; &lt;p&gt;We can see from the PyPI result analysis that from TensorFlow 1.13.0 (&lt;code&gt;2k-test-new&lt;/code&gt; inspection batch) to TensorFlow 1.14.0 (&lt;code&gt;test-ms&lt;/code&gt; inspection batch) there is a ~1.46x improvement considering the median of the rate (GFLOPS) results from matmul using matrix sizes of 512 and only CPU. We also need to consider the variation on the results for further tests, also considering an optimization on the number of inspections to run to guarantee low result error.&lt;/p&gt; &lt;p&gt;In general, these results show the potential of Thoth&amp;#8217;s infrastructure running in Openshift on PSI and how it can collect performance observations. They give good insights on how the tests need to be run, but further analysis needs to be performed to reduce the variation of the errors in order to avoid misleading recommendations.&lt;/p&gt; &lt;h2&gt;Next steps&lt;/h2&gt; &lt;p&gt;Next, we plan to:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Perform other types of tests on the same PI.&lt;/li&gt; &lt;li&gt;Aggregate other results considering different PIs.&lt;/li&gt; &lt;li&gt;Create new PI for ML applications.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F28%2Fmicrobenchmarks-for-ai-applications-using-red-hat-openshift-on-psi-in-project-thoth%2F&amp;#38;linkname=Microbenchmarks%20for%20AI%20applications%20using%20Red%20Hat%20OpenShift%20on%20PSI%20in%20project%20Thoth" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F28%2Fmicrobenchmarks-for-ai-applications-using-red-hat-openshift-on-psi-in-project-thoth%2F&amp;#38;linkname=Microbenchmarks%20for%20AI%20applications%20using%20Red%20Hat%20OpenShift%20on%20PSI%20in%20project%20Thoth" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F28%2Fmicrobenchmarks-for-ai-applications-using-red-hat-openshift-on-psi-in-project-thoth%2F&amp;#38;linkname=Microbenchmarks%20for%20AI%20applications%20using%20Red%20Hat%20OpenShift%20on%20PSI%20in%20project%20Thoth" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F28%2Fmicrobenchmarks-for-ai-applications-using-red-hat-openshift-on-psi-in-project-thoth%2F&amp;#38;linkname=Microbenchmarks%20for%20AI%20applications%20using%20Red%20Hat%20OpenShift%20on%20PSI%20in%20project%20Thoth" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F28%2Fmicrobenchmarks-for-ai-applications-using-red-hat-openshift-on-psi-in-project-thoth%2F&amp;#38;linkname=Microbenchmarks%20for%20AI%20applications%20using%20Red%20Hat%20OpenShift%20on%20PSI%20in%20project%20Thoth" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F28%2Fmicrobenchmarks-for-ai-applications-using-red-hat-openshift-on-psi-in-project-thoth%2F&amp;#38;linkname=Microbenchmarks%20for%20AI%20applications%20using%20Red%20Hat%20OpenShift%20on%20PSI%20in%20project%20Thoth" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F28%2Fmicrobenchmarks-for-ai-applications-using-red-hat-openshift-on-psi-in-project-thoth%2F&amp;#38;linkname=Microbenchmarks%20for%20AI%20applications%20using%20Red%20Hat%20OpenShift%20on%20PSI%20in%20project%20Thoth" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F28%2Fmicrobenchmarks-for-ai-applications-using-red-hat-openshift-on-psi-in-project-thoth%2F&amp;#038;title=Microbenchmarks%20for%20AI%20applications%20using%20Red%20Hat%20OpenShift%20on%20PSI%20in%20project%20Thoth" data-a2a-url="https://developers.redhat.com/blog/2019/10/28/microbenchmarks-for-ai-applications-using-red-hat-openshift-on-psi-in-project-thoth/" data-a2a-title="Microbenchmarks for AI applications using Red Hat OpenShift on PSI in project Thoth"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/10/28/microbenchmarks-for-ai-applications-using-red-hat-openshift-on-psi-in-project-thoth/"&gt;Microbenchmarks for AI applications using Red Hat OpenShift on PSI in project Thoth&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/WfnAImyJSxw" height="1" width="1" alt=""/&gt;</content><summary>Project Thoth is an artificial intelligence (AI) R&amp;D Red Hat research project as part of the Office of the CTO and the AI Center of Excellence (CoE). This project aims to build a knowledge graph and a recommendation system for application stacks based on the collected knowledge, such as machine learning (ML) applications that rely on popular open source ML frameworks and libraries (TensorFlow, PyT...</summary><dc:creator>Francesco Murdaca</dc:creator><dc:date>2019-10-28T07:00:56Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2019/10/28/microbenchmarks-for-ai-applications-using-red-hat-openshift-on-psi-in-project-thoth/</feedburner:origLink></entry><entry><title>Python 2 support is going away soon: Make the move to Python 3</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/XRYZ1cSeKBU/" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="Programming Languages" scheme="searchisko:content:tags" /><category term="Python" scheme="searchisko:content:tags" /><category term="Python 3" scheme="searchisko:content:tags" /><author><name>Langdon White</name></author><id>searchisko:content:id:jbossorg_blog-python_2_support_is_going_away_soon_make_the_move_to_python_3</id><updated>2019-10-25T07:00:04Z</updated><published>2019-10-25T07:00:04Z</published><content type="html">&lt;p&gt;Seeing &lt;a href="https://twitter.com/gvanrossum/status/1170949978036084736"&gt;this tweet from Guido van Rossum&lt;/a&gt; the other day prompted me to write this &amp;#8220;OMG, Python 2 is going away SOON&amp;#8221; article. You have definitely heard it before, but seriously, folks, the Python upstream community is ending support for Python 2 at the end of the year!&lt;/p&gt; &lt;p&gt;Let&amp;#8217;s stop saying &amp;#8220;2020&amp;#8221; because that sounds far away when, in fact, we are talking about January 1, 2020, which is two and half months from now. In this article, I&amp;#8217;ll provide some quick links and basic information to help you make the move to &lt;a href="https://www.python.org/download/releases/3.0/"&gt;Python 3&lt;/a&gt;.&lt;span id="more-642947"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;Moving to Python 3&lt;/h2&gt; &lt;p&gt;I hope that you have already been convinced about why you should move to Python 3 but, if not, you should definitely check out &lt;a href="https://twitter.com/ncoghlan_dev"&gt;Nick Coghlan’&lt;/a&gt;s &lt;a href="https://ncoghlan-devs-python-notes.readthedocs.io/en/latest/python3/questions_and_answers.html"&gt;Python 3 Q&amp;#38;A&lt;/a&gt; and &lt;a href="https://twitter.com/brettsky"&gt;Brett Cannon&lt;/a&gt;’s &lt;a href="https://snarky.ca/why-python-3-exists"&gt;Why Python 3 exists&lt;/a&gt; (as recommended by the &lt;a href="https://docs.python.org/3/howto/pyporting.html"&gt;Python porting page&lt;/a&gt;). Speaking from my own experience, I find Python 3 to be &lt;strong&gt;much&lt;/strong&gt; more consistent in language constructs and way more in line with the &amp;#8220;&lt;a href="https://www.python.org/dev/peps/pep-0206/#batteries-included-philosophy"&gt;batteries included&lt;/a&gt;&amp;#8221; philosophy.&lt;/p&gt; &lt;p&gt;Personally, my hesitation would be directly related to how much of the ecosystem is already on Python 3. In other words, language adoption is often more about the ecosystem than it is about the language itself.&lt;/p&gt; &lt;h2&gt;The ecosystem is ready&lt;/h2&gt; &lt;p&gt;Let me assure you; the ecosystem is &lt;strong&gt;ready&lt;/strong&gt;. According to the &lt;a href="https://fedora.portingdb.xyz/"&gt;Python Porting DB&lt;/a&gt; nearly 90% of Fedora Python Libraries support Python 3. Perhaps more concerning for those of you who are still on Python 2, 80% of the libraries &lt;strong&gt;only&lt;/strong&gt; support Python 3. If you have any doubts about the particular libraries you need, you can use the &lt;a href="https://pypi.org/project/caniusepython3"&gt;caniusepython3 &lt;/a&gt;tool to be sure.&lt;/p&gt; &lt;p&gt;If you are worried about how much work it will be to move to Python 3, well, the Python Community has also gone to great lengths to make it as easy as possible. Specifically, check out tools like &lt;a href="http://python-future.org/automatic_conversion.html"&gt;Futurize&lt;/a&gt; (which passes Python 2 code through appropriate fixers and turns it into valid Python 3 code) and &lt;a href="https://python-modernize.readthedocs.io/"&gt;Modernize&lt;/a&gt; (which makes Python 2 code more modern for porting to Python 3). The community has also provided a linter that will prove to you that you have cleaned everything up.&lt;/p&gt; &lt;p&gt;However, all that said, there is always the problem of testing. No one at Red Hat or in the Python community can help you create tests that don&amp;#8217;t exist. If you don&amp;#8217;t have great test coverage, maybe this can be an opportunity to add tests. Then, the next time you want to do a refactor or introduce a new feature, you don&amp;#8217;t have to be so frightened :).&lt;/p&gt; &lt;h2&gt;Heed the call&lt;/h2&gt; &lt;p&gt;All in all, now&amp;#8217;s the time to heed Guido&amp;#8217;s call to action. Everything is ready for you to move. And, you really shouldn&amp;#8217;t have to do this again for a good long time, because Python 3 will be supported until the end of the &lt;a href="https://www.redhat.com/en/enterprise-linux-8"&gt;Red Hat Enterprise Linux 8&lt;/a&gt; lifecycle. If you can&amp;#8217;t commit quite yet, we still have your back for a couple more years with our expected &lt;a href="https://access.redhat.com/node/4079021"&gt;retirement of Python27&lt;/a&gt; in 2024.&lt;/p&gt; &lt;h3&gt;Other resources&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/products/softwarecollections/overview"&gt;Red Hat Software Collections&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2019/05/07/what-no-python-in-red-hat-enterprise-linux-8/"&gt;What, no Python in Red Hat Enterprise Linux 8?&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2018/08/13/install-python3-rhel/"&gt;How to install Python 3 on Red Hat Enterprise Linux&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2019/09/11/develop-with-django-2-and-python-3-in-a-container-with-red-hat-enterprise-linux/"&gt;Develop with Django 2 and Python 3 in a container with Red Hat Enterprise Linux&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F25%2Fpython-2-support-is-going-away-soon-make-the-move-to-python-3%2F&amp;#38;linkname=Python%202%20support%20is%20going%20away%20soon%3A%20Make%20the%20move%20to%20Python%203" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F25%2Fpython-2-support-is-going-away-soon-make-the-move-to-python-3%2F&amp;#38;linkname=Python%202%20support%20is%20going%20away%20soon%3A%20Make%20the%20move%20to%20Python%203" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F25%2Fpython-2-support-is-going-away-soon-make-the-move-to-python-3%2F&amp;#38;linkname=Python%202%20support%20is%20going%20away%20soon%3A%20Make%20the%20move%20to%20Python%203" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F25%2Fpython-2-support-is-going-away-soon-make-the-move-to-python-3%2F&amp;#38;linkname=Python%202%20support%20is%20going%20away%20soon%3A%20Make%20the%20move%20to%20Python%203" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F25%2Fpython-2-support-is-going-away-soon-make-the-move-to-python-3%2F&amp;#38;linkname=Python%202%20support%20is%20going%20away%20soon%3A%20Make%20the%20move%20to%20Python%203" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F25%2Fpython-2-support-is-going-away-soon-make-the-move-to-python-3%2F&amp;#38;linkname=Python%202%20support%20is%20going%20away%20soon%3A%20Make%20the%20move%20to%20Python%203" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F25%2Fpython-2-support-is-going-away-soon-make-the-move-to-python-3%2F&amp;#38;linkname=Python%202%20support%20is%20going%20away%20soon%3A%20Make%20the%20move%20to%20Python%203" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F25%2Fpython-2-support-is-going-away-soon-make-the-move-to-python-3%2F&amp;#038;title=Python%202%20support%20is%20going%20away%20soon%3A%20Make%20the%20move%20to%20Python%203" data-a2a-url="https://developers.redhat.com/blog/2019/10/25/python-2-support-is-going-away-soon-make-the-move-to-python-3/" data-a2a-title="Python 2 support is going away soon: Make the move to Python 3"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/10/25/python-2-support-is-going-away-soon-make-the-move-to-python-3/"&gt;Python 2 support is going away soon: Make the move to Python 3&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/XRYZ1cSeKBU" height="1" width="1" alt=""/&gt;</content><summary>Seeing this tweet from Guido van Rossum the other day prompted me to write this “OMG, Python 2 is going away SOON” article. You have definitely heard it before, but seriously, folks, the Python upstream community is ending support for Python 2 at the end of the year! Let’s stop saying “2020” because that sounds far away when, in fact, we are talking about January 1, 2020, which is two and half mon...</summary><dc:creator>Langdon White</dc:creator><dc:date>2019-10-25T07:00:04Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2019/10/25/python-2-support-is-going-away-soon-make-the-move-to-python-3/</feedburner:origLink></entry><entry><title>Bring joy to development with Quarkus, the cloud-native Java framework</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/De1kQVeCM_o/" /><category term="devnation" scheme="searchisko:content:tags" /><category term="events" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="Java" scheme="searchisko:content:tags" /><category term="quarkus" scheme="searchisko:content:tags" /><author><name>Editorial Team</name></author><id>searchisko:content:id:jbossorg_blog-bring_joy_to_development_with_quarkus_the_cloud_native_java_framework</id><updated>2019-10-24T07:00:40Z</updated><published>2019-10-24T07:00:40Z</published><content type="html">&lt;p&gt;Our first &lt;a href="https://developers.redhat.com/devnationlive-india/"&gt;DevNation Live regional event was held in Bengaluru, India&lt;/a&gt; in July. This free technology event focused on open source innovations, with sessions presented by elite Red Hat technologists.&lt;/p&gt; &lt;p class="selectionShareable"&gt;&lt;a href="https://developers.redhat.com/blog/2019/03/07/quarkus-next-generation-kubernetes-native-java-framework/"&gt;Quarkus&lt;/a&gt; is revolutionizing the way that we develop &lt;a href="https://developers.redhat.com/developer-tools/java"&gt;Java&lt;/a&gt; applications for the cloud-native era, and in this presentation, &lt;a href="https://developers.redhat.com/blog/author/yanaga/"&gt;Edson Yanaga&lt;/a&gt; explains why it also sparks joy. &lt;span id="more-627017"&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;Watch this live coding session to get familiar with Quarkus and learn how your old and new favorite APIs will start in a matter of milliseconds and consume tiny amounts of memory. Hot reload capabilities for development will bring you instant joy.&lt;/p&gt; &lt;p&gt;Watch the complete presentation:&lt;br /&gt; &lt;iframe src="https://www.youtube.com/embed/GZzcjVZ-WMQ" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"&gt;&lt;/iframe&gt;&lt;/p&gt; &lt;p&gt;&lt;a href="https://speakerdeck.com/yanaga/coding-that-sparks-joy-with-quarkus"&gt;See the slides here.&lt;/a&gt;&lt;/p&gt; &lt;h3&gt;&lt;b&gt;Learn more&lt;/b&gt;&lt;/h3&gt; &lt;p&gt;Join us at an upcoming&lt;a href="https://developers.redhat.com/events/"&gt; developer event&lt;/a&gt;, and see our collection of&lt;a href="https://developers.redhat.com/devnation/?page=0"&gt; past DevNation Live tech talks&lt;/a&gt;&lt;a href="https://developers.redhat.com/events/"&gt;.&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F24%2Fbring-joy-to-development-with-quarkus-the-cloud-native-java-framework%2F&amp;#38;linkname=Bring%20joy%20to%20development%20with%20Quarkus%2C%20the%20cloud-native%20Java%20framework" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F24%2Fbring-joy-to-development-with-quarkus-the-cloud-native-java-framework%2F&amp;#38;linkname=Bring%20joy%20to%20development%20with%20Quarkus%2C%20the%20cloud-native%20Java%20framework" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F24%2Fbring-joy-to-development-with-quarkus-the-cloud-native-java-framework%2F&amp;#38;linkname=Bring%20joy%20to%20development%20with%20Quarkus%2C%20the%20cloud-native%20Java%20framework" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F24%2Fbring-joy-to-development-with-quarkus-the-cloud-native-java-framework%2F&amp;#38;linkname=Bring%20joy%20to%20development%20with%20Quarkus%2C%20the%20cloud-native%20Java%20framework" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F24%2Fbring-joy-to-development-with-quarkus-the-cloud-native-java-framework%2F&amp;#38;linkname=Bring%20joy%20to%20development%20with%20Quarkus%2C%20the%20cloud-native%20Java%20framework" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F24%2Fbring-joy-to-development-with-quarkus-the-cloud-native-java-framework%2F&amp;#38;linkname=Bring%20joy%20to%20development%20with%20Quarkus%2C%20the%20cloud-native%20Java%20framework" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F24%2Fbring-joy-to-development-with-quarkus-the-cloud-native-java-framework%2F&amp;#38;linkname=Bring%20joy%20to%20development%20with%20Quarkus%2C%20the%20cloud-native%20Java%20framework" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F24%2Fbring-joy-to-development-with-quarkus-the-cloud-native-java-framework%2F&amp;#038;title=Bring%20joy%20to%20development%20with%20Quarkus%2C%20the%20cloud-native%20Java%20framework" data-a2a-url="https://developers.redhat.com/blog/2019/10/24/bring-joy-to-development-with-quarkus-the-cloud-native-java-framework/" data-a2a-title="Bring joy to development with Quarkus, the cloud-native Java framework"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/10/24/bring-joy-to-development-with-quarkus-the-cloud-native-java-framework/"&gt;Bring joy to development with Quarkus, the cloud-native Java framework&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/De1kQVeCM_o" height="1" width="1" alt=""/&gt;</content><summary>Our first DevNation Live regional event was held in Bengaluru, India in July. This free technology event focused on open source innovations, with sessions presented by elite Red Hat technologists. Quarkus is revolutionizing the way that we develop Java applications for the cloud-native era, and in this presentation, Edson Yanaga explains why it also sparks joy. Watch this live coding session to ge...</summary><dc:creator>Editorial Team</dc:creator><dc:date>2019-10-24T07:00:40Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2019/10/24/bring-joy-to-development-with-quarkus-the-cloud-native-java-framework/</feedburner:origLink></entry><entry><title>Using a MySQL database in your Red Hat OpenShift application</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/Cb6_meOlT04/" /><category term="Containers" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="microservices" scheme="searchisko:content:tags" /><category term="mysql" scheme="searchisko:content:tags" /><category term="openshift" scheme="searchisko:content:tags" /><author><name>Don Schenck</name></author><id>searchisko:content:id:jbossorg_blog-using_a_mysql_database_in_your_red_hat_openshift_application</id><updated>2019-10-23T07:00:52Z</updated><published>2019-10-23T07:00:52Z</published><content type="html">&lt;p&gt;Creating &lt;a href="https://developers.redhat.com/blog/2019/07/18/mysql-for-developers-in-red-hat-openshift/"&gt;a MySQL database in Red Hat OpenShift&lt;/a&gt; is useful for developers, there&amp;#8217;s no doubt about that. But, once the database is ready, with tables and data, how do you use the data in your application? Is there some special magic when using Red Hat OpenShift? What about the fact that pod names can change? This article will walk you through the steps necessary to access a MySQL database that is running in your &lt;a href="https://developers.redhat.com/openshift/"&gt;OpenShift&lt;/a&gt; cluster.&lt;br /&gt; &lt;span id="more-610967"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;There is code&lt;/h2&gt; &lt;p&gt;The code to accompany this blog post is available at &lt;a href="https://github.com/redhat-developer-demos/mysql-openshift-ephemeral.git"&gt;the associated GitHub repo&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Let&amp;#8217;s get a database&lt;/h2&gt; &lt;p&gt;The first step — after creating an OpenShift cluster — is to create a MySQL database in OpenShift. &lt;a href="https://developers.redhat.com/blog/2019/07/18/mysql-for-developers-in-red-hat-openshift/"&gt;My previous article&lt;/a&gt; describes how to create an ephemeral MySQL database in your OpenShift cluster. For the sake of this article, we make the following assumptions:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;The cluster name is &lt;em&gt;mysql.&lt;/em&gt;&lt;/li&gt; &lt;li&gt;The project name is &lt;em&gt;mysqsl-test.&lt;/em&gt;&lt;/li&gt; &lt;li&gt;The database name is &lt;em&gt;sampledb.&lt;/em&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;If you change any of these values, you&amp;#8217;ll need to change commands and scripts as necessary.&lt;/p&gt; &lt;h2&gt;Database up and running&lt;/h2&gt; &lt;p&gt;By following the previous article, you will now have a database up and running in OpenShift. In that article, we named the MySQL database instance &lt;em&gt;mysql&lt;/em&gt;.  This is important; if you used a different name, make note of it, as we&amp;#8217;ll need it soon.&lt;/p&gt; &lt;h2&gt;The services&lt;/h2&gt; &lt;p&gt;For this demo, we&amp;#8217;re going to run two very simple microservices, &lt;em&gt;getCustomer&lt;/em&gt; and &lt;em&gt;getCustomerSummaryList&lt;/em&gt;, in pods in our OpenShift cluster. The source code for these services exists in a directory in &lt;a href="https://github.com/redhat-developer-demos/mysql-openshift-ephemeral"&gt;a GitHub repo&lt;/a&gt; (mentioned previously), so rather than create an image on our local machine and push it to our cluster, we&amp;#8217;ll use OpenShift&amp;#8217;s slick Source-to-Image (or S2I) build feature.&lt;/p&gt; &lt;p&gt;The S2I feature allows you to reference a GitHub repo in OpenShift and trigger automatic builds from source. OpenShift will fetch the source code, analyze it, and build it according to what type of source code it is (e.g., Node.js, Ruby, etc.). The resulting image will be stored in the OpenShift cluster&amp;#8217;s internal registry.&lt;/p&gt; &lt;p&gt;You can optionally configure your GitHub repo to post a webhook to your OpenShift cluster whenever a pull request is approved, triggering a rebuild of the OpenShift-hosted image.&lt;/p&gt; &lt;p&gt;To build our microservices from source, we&amp;#8217;ll use the following commands.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; You need to alter the MYSQL_USER and MYSQL_PASSWORD values to match the credentials that were supplied when you created the database (in the previous article). If you don&amp;#8217;t have those values, you&amp;#8217;ll need to add a user with the proper rights to your MySQL instance.&lt;/p&gt; &lt;pre&gt;oc new-app https://github.com/redhat-developer-demos/mysql-openshift-ephemeral.git --context-dir=src/getCustomer --name getcustomer -e MYSQL_HOST=mysql -e MYSQL_DATABASE=sampledb -e MYSQL_USER=mysql_userid_goes_here -e MYSQL_PASSWORD=mysql_password_goes_here&lt;/pre&gt; &lt;pre&gt;oc new-app https://github.com/redhat-developer-demos/mysql-openshift-ephemeral.git --context-dir=src/getCustomerSummaryList --name getcustomersummarylist -e MYSQL_HOST=mysql -e MYSQL_DATABASE=sampledb -e MYSQL_USER=mysql_userid_goes_here -e MYSQL_PASSWORD=mysql_password_goes_here&lt;/pre&gt; &lt;p&gt;These two commands will launch builds inside your OpenShift cluster that should take about a minute. If you run &lt;code&gt;oc get pods&lt;/code&gt;, you can see them running. When they&amp;#8217;re finished, we have to services running in our OpenShift cluster. They are not reachable from outside the cluster; this is by design. We&amp;#8217;re going to add a website to the cluster as well. That website will use these two services, and we&amp;#8217;ll expose the website to the world via a public IP address and URL.&lt;/p&gt; &lt;h2&gt;The website&lt;/h2&gt; &lt;p&gt;To create the website, we&amp;#8217;ll use a different method. Rather than use source code, we&amp;#8217;ll pull a Linux image into OpenShift. The following command will pull the image into the OpenShift cluster&amp;#8217;s internal image registry and start it.&lt;/p&gt; &lt;pre&gt;oc new-app --name mvccustomer --docker-image=quay.io/donschenck/mvccustomer:latest -e GET_CUSTOMER_SUMMARY_LIST_URI="http://getcustomersummarylist:8080/customers" -e GET_CUSTOMER_URI="http://getcustomer:8080/customer"&lt;/pre&gt; &lt;p&gt;Note that we&amp;#8217;re supplying environment variables that define the path, inside OpenShift, to the two services we just built.&lt;/p&gt; &lt;p&gt;There&amp;#8217;s one more small step. We need to expose this website to the world so can browse to it from our desktop browser. We do that, and create a &amp;#8220;route&amp;#8221; in OpenShift, by using the following command:&lt;/p&gt; &lt;pre&gt;oc expose service mvccustomer --insecure-skip-tls-verify=false&lt;/pre&gt; &lt;p&gt;At this point, you have two microservices that will retrieve a customer list and a single customer from your MySQL database, running in OpenShift — as is our ephemeral MySQL database. We also have a website that uses these two services. We can see the URL for our website by running the following command:&lt;/p&gt; &lt;pre&gt;oc get routes&lt;/pre&gt; &lt;p&gt;Looking at the URI, you can see the obvious parts that refer to my service, my project, my cluster, and my domain. The URI format is as follows:&lt;/p&gt; &lt;pre&gt;http://{service_name}-{project-name}.app.{cluster_name}.{domain_name}&lt;/pre&gt; &lt;p&gt;Remember when I mentioned, in the &amp;#8220;Let&amp;#8217;s get a database&amp;#8221; section above, how we assumed some names? Well, if you did decide to change things up, you would notice it here.&lt;/p&gt; &lt;h2&gt;Discovery&lt;/h2&gt; &lt;p&gt;This idea, that you can know ahead of time what the URI will be, is thanks to Kubernetes&amp;#8217; feature known as &amp;#8220;Service Discovery.&amp;#8221; Because you assign a name to service, Kubernetes will keep track of the pods associated with it, even if the pod names change (e.g., a pod is deleted and replaced by a new pod). Even better: As you scale up to multiple pods, you still have only one URI. Kubernetes takes care of the load balancing between the pods.&lt;/p&gt; &lt;h2&gt;Launching the website&lt;/h2&gt; &lt;p&gt;Simply paste the URL into your browser and start clicking.&lt;/p&gt; &lt;p&gt;&lt;img class=" alignnone size-full wp-image-639757 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/10/mvccustomer.gif" src="https://developers.redhat.com/blog/wp-content/uploads/2019/10/mvccustomer.gif" alt="" width="962" height="577" /&gt;&lt;/p&gt; &lt;h2&gt;What&amp;#8217;s next?&lt;/h2&gt; &lt;p&gt;The next step is to create a permanent (i.e., &lt;em&gt;not&lt;/em&gt; ephemeral) MySQL instance running in Red Hat OpenShift. That&amp;#8217;s yet another article.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F23%2Fusing-a-mysql-database-in-your-red-hat-openshift-application%2F&amp;#38;linkname=Using%20a%20MySQL%20database%20in%20your%20Red%20Hat%20OpenShift%20application" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F23%2Fusing-a-mysql-database-in-your-red-hat-openshift-application%2F&amp;#38;linkname=Using%20a%20MySQL%20database%20in%20your%20Red%20Hat%20OpenShift%20application" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F23%2Fusing-a-mysql-database-in-your-red-hat-openshift-application%2F&amp;#38;linkname=Using%20a%20MySQL%20database%20in%20your%20Red%20Hat%20OpenShift%20application" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F23%2Fusing-a-mysql-database-in-your-red-hat-openshift-application%2F&amp;#38;linkname=Using%20a%20MySQL%20database%20in%20your%20Red%20Hat%20OpenShift%20application" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F23%2Fusing-a-mysql-database-in-your-red-hat-openshift-application%2F&amp;#38;linkname=Using%20a%20MySQL%20database%20in%20your%20Red%20Hat%20OpenShift%20application" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F23%2Fusing-a-mysql-database-in-your-red-hat-openshift-application%2F&amp;#38;linkname=Using%20a%20MySQL%20database%20in%20your%20Red%20Hat%20OpenShift%20application" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F23%2Fusing-a-mysql-database-in-your-red-hat-openshift-application%2F&amp;#38;linkname=Using%20a%20MySQL%20database%20in%20your%20Red%20Hat%20OpenShift%20application" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F23%2Fusing-a-mysql-database-in-your-red-hat-openshift-application%2F&amp;#038;title=Using%20a%20MySQL%20database%20in%20your%20Red%20Hat%20OpenShift%20application" data-a2a-url="https://developers.redhat.com/blog/2019/10/23/using-a-mysql-database-in-your-red-hat-openshift-application/" data-a2a-title="Using a MySQL database in your Red Hat OpenShift application"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/10/23/using-a-mysql-database-in-your-red-hat-openshift-application/"&gt;Using a MySQL database in your Red Hat OpenShift application&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/Cb6_meOlT04" height="1" width="1" alt=""/&gt;</content><summary>Creating a MySQL database in Red Hat OpenShift is useful for developers, there’s no doubt about that. But, once the database is ready, with tables and data, how do you use the data in your application? Is there some special magic when using Red Hat OpenShift? What about the fact that pod names can change? This article will walk you through the steps necessary to access a MySQL database that is run...</summary><dc:creator>Don Schenck</dc:creator><dc:date>2019-10-23T07:00:52Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2019/10/23/using-a-mysql-database-in-your-red-hat-openshift-application/</feedburner:origLink></entry><entry><title>Introducing jBPM's Human Task recommendation API</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/MIasCImfmlA/introducing-jbpms-human-task.html" /><category term="feed_group_name_jbossjbpmcommunity" scheme="searchisko:content:tags" /><category term="feed_name_swiderskimaciej" scheme="searchisko:content:tags" /><author><name>Rui Vieira</name></author><id>searchisko:content:id:jbossorg_blog-introducing_jbpm_s_human_task_recommendation_api</id><updated>2019-10-22T16:58:22Z</updated><published>2019-10-22T16:58:00Z</published><content type="html">In this post, we’ll introduce a new jBPM API which allows for predictive models to be trained with Human Tasks (HT) data and for HT to incorporate model predictions as outputs and complete HT without user interaction.&lt;br /&gt;&lt;br /&gt;This API will allow you to add Machine Learning capabilities to your jBPM project by being able to use, for instance, models trained with historical task data to recommend the most likely output. The API also gives developers the flexibility to implement a “recommendation-only” service (which only suggests outputs) as well as automatically completing the task if the prediction’s confidence meets a user-defined prediction confidence threshold.&lt;br /&gt;This API exposes the HT handling to a &lt;i&gt;recommendation service&lt;/i&gt;.&lt;br /&gt;A recommendation service is simply any third-party class which implements the &lt;code&gt;org.kie.internal.task.api.prediction.PredictionService&lt;/code&gt; interface.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://1.bp.blogspot.com/-6Qs6lgmW4Dc/Xa8gzTDUx2I/AAAAAAABJQ0/Z6EBqHxP1f0SuZXoWrpRk4UvzBSjyuFmACLcBGAsYHQ/s1600/api.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="281" data-original-width="800" height="224" src="https://1.bp.blogspot.com/-6Qs6lgmW4Dc/Xa8gzTDUx2I/AAAAAAABJQ0/Z6EBqHxP1f0SuZXoWrpRk4UvzBSjyuFmACLcBGAsYHQ/s640/api.png" width="640" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;&lt;br /&gt;&amp;nbsp;This interface consists of three methods:&lt;br /&gt;&lt;br /&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;getIdentifier()&lt;/code&gt; - a method which returns a unique (&lt;code&gt;String&lt;/code&gt;) identifier for your prediction service&lt;/li&gt;&lt;li&gt;&lt;code&gt;predict(Task task, Map&amp;lt;String, Object&amp;gt; inputData)&lt;/code&gt; - a method that takes task information and the task's inputs from which we will derive the model's inputs, as a map. The method returns a &lt;code&gt;PredictionOutcome&lt;/code&gt; instance, which we will look in closer detail later on&lt;/li&gt;&lt;li&gt;&lt;code&gt;train(Task task, Map&amp;lt;String, Object&amp;gt; inputData, Map&amp;lt;String, Object&amp;gt; outputData)&lt;/code&gt; - this method, similarly to predict, takes task info and the task's inputs, but now we also need to provide the task's outputs, as a map, for training&amp;nbsp; &lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;This class will consist of:&lt;br /&gt;&lt;br /&gt;&lt;ul&gt;&lt;li&gt;A &lt;code&gt;Map&amp;lt;String, Object&amp;gt;&lt;/code&gt; outcome containing the prediction outputs, each entry represents an output attribute’s name and value. This map can be empty, which corresponds to the model not providing any prediction.&lt;/li&gt;&lt;li&gt;A &lt;code&gt;confidence&lt;/code&gt; value. The meaning of this field is left to the developer (&lt;i&gt;e.g.&lt;/i&gt; it could represent a probability between 0.0 and 1.0). It's relevance is related to the &lt;code&gt;confidenceThreshold&lt;/code&gt; below.&lt;/li&gt;&lt;li&gt;A &lt;code&gt;confidenceThreshold&lt;/code&gt; - this value represents the confidence cutoff after which an action can be taken by the HT item handler.&lt;/li&gt;&lt;/ul&gt;As an example, let's assume our confidence represents a prediction probability between 0.0 and 1.0. If the &lt;code&gt;confidenceThreshold&lt;/code&gt; is 0.7, that would mean that for &lt;code&gt;confidence &amp;gt; 0.7&lt;/code&gt; the HT outputs would be set to the outcome and the task automatically closed. If the &lt;code&gt;confidence &amp;lt;= 0.7&lt;/code&gt;, then the HT would set the prediction outcome as suggested values, but the task would not be closed and still need human interaction. If the outcome is empty, then the HT life cycle would proceed as if no prediction was made.&lt;br /&gt;By defining a confidence threshold which is always higher than the confidence, developers can create a “recommendation-only” service, which will assign predicted outputs to the task, but never complete it.&lt;br /&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;/div&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://1.bp.blogspot.com/-DCLFhNIKzW4/Xa8ht2nGCQI/AAAAAAABJRA/c6ZyjiN5C0c5oFhU8iH1qQk7FnF7Frz2ACLcBGAsYHQ/s1600/sequence.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="403" data-original-width="800" height="322" src="https://1.bp.blogspot.com/-DCLFhNIKzW4/Xa8ht2nGCQI/AAAAAAABJRA/c6ZyjiN5C0c5oFhU8iH1qQk7FnF7Frz2ACLcBGAsYHQ/s640/sequence.png" width="640" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;&lt;br /&gt;The initial step is then, as defined above, the &lt;code&gt;predict&lt;/code&gt; step. In the scenario where the prediction's confidence is above the threshold, the task is automatically completed. If the confidence is not above the threshold, however, when the task is eventually completed both the inputs and the outputs will then be used to further train the model by calling the prediction service's &lt;code&gt;train&lt;/code&gt; method.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://1.bp.blogspot.com/-YFL5vL--Zxw/Xa8iJymzMII/AAAAAAABJRI/u6-UeCFkhV41Z0iVosy1cS6m4_4UMrvwgCLcBGAsYHQ/s1600/sequence_train.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="546" data-original-width="800" height="436" src="https://1.bp.blogspot.com/-YFL5vL--Zxw/Xa8iJymzMII/AAAAAAABJRI/u6-UeCFkhV41Z0iVosy1cS6m4_4UMrvwgCLcBGAsYHQ/s640/sequence_train.png" width="640" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;&lt;h3&gt;Example project&lt;/h3&gt;&lt;br /&gt;An example project is available &lt;a href="https://github.com/ruivieira/jbpm-recommendation-demo"&gt;here&lt;/a&gt;. This project consists of a single Human Task, which can be inspected using Business Central. The task is generic and simple enough in order to demonstrate the working of the jBPM's recommendation API.&lt;br /&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;/div&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://1.bp.blogspot.com/-Gmzu4gvWIGg/Xa8iikBPHGI/AAAAAAABJRQ/GR4nEIylpsoYNXrQYiLOWddDIc_U6FNTQCLcBGAsYHQ/s1600/human_task.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="223" data-original-width="866" height="102" src="https://1.bp.blogspot.com/-Gmzu4gvWIGg/Xa8iikBPHGI/AAAAAAABJRQ/GR4nEIylpsoYNXrQYiLOWddDIc_U6FNTQCLcBGAsYHQ/s400/human_task.png" width="400" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;&lt;br /&gt;For the purposes of the demonstration, this task will be used to model a simple purchasing system where the purchase of a laptop of a certain brand is requested and must be, eventually, manually approved. The tasks &lt;b&gt;inputs&lt;/b&gt; are:&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;item&lt;/code&gt; - a &lt;code&gt;String&lt;/code&gt; with the brand's name&lt;/li&gt;&lt;li&gt;&lt;code&gt;price&lt;/code&gt; - a &lt;code&gt;Float&lt;/code&gt; representing the laptop's price&lt;/li&gt;&lt;li&gt;&lt;code&gt;ActorId&lt;/code&gt; - a &lt;code&gt;String&lt;/code&gt; representing the user requesting the purchase&lt;br /&gt; &lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;&lt;br /&gt;The task provides as &lt;b&gt;outputs&lt;/b&gt;:&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;approved&lt;/code&gt; - a &lt;code&gt;Boolean&lt;/code&gt; specifying whether the purchase was approved or not&lt;br /&gt; &lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;&lt;br /&gt;This repository contains two example recommendation service implementations as Maven modules and a REST client to populate the project with tasks to allow the predictive model training.&lt;br /&gt;&lt;br /&gt;Start by downloading, or alternatively cloning, the repository:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;$ git clone &lt;a href="mailto:git@github.com"&gt;git@github.com&lt;/a&gt;:ruivieira/jbpm-recommendation-demo.git&lt;/pre&gt;&lt;pre&gt;&amp;nbsp;&lt;/pre&gt;For this demo, two random forest-based services, one using the&lt;a href="https://github.com/haifengl/smile"&gt; SMILE&lt;/a&gt; library and another as a Predictive Model Markup Language (&lt;a href="https://en.wikipedia.org/wiki/Predictive_Model_Markup_Language"&gt;PMML&lt;/a&gt;) model, will be used. The services, located respectively in &lt;code&gt;services/jbpm-recommendation-smile-random-forest&lt;/code&gt; and &lt;code&gt;services/jbpm-recommendation-pmml-random-forest&lt;/code&gt;, can be built with (using SMILE as an example):&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;$ cd services/jbpm-recommendation-smile-random-forest&lt;br /&gt;$ mvn clean install&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;The resulting JARs files can then be included in the Business Central’s &lt;code&gt;kie-server.war&lt;/code&gt; located in &lt;code&gt;standalone/deployments&lt;/code&gt; directory of your jBPM server installation. To do this, simply create a &lt;code&gt;WEB-INF/lib&lt;/code&gt;, copy the compiled JARs into it and run&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;$ zip -r kie-server.war WEB-INF&lt;br /&gt;&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;The PMML-based service expects to find the PMML model in &lt;code&gt;META-INF&lt;/code&gt;, so after copying the PMML file in &lt;code&gt;jbpm-recommendation-pmml-random-forest/src/main/resources/models/random_forest.pmml&lt;/code&gt; into &lt;code&gt;META-INF&lt;/code&gt;, it should also be included in the WAR by using&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;$ zip -r kie-server.war META-INF&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;jBPM will search for a recommendation service with an identifier specified by a Java property named &lt;code&gt;org.jbpm.task.prediction.service&lt;/code&gt;. Since in our demo, the random forest service has the identifier &lt;code&gt;SMILERandomForest&lt;/code&gt;, we can set this value when starting Business Central, for instance as:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;$ ./standalone.sh -Dorg.jbpm.task.prediction.service=SMILERandomForest&lt;br /&gt;&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;For the purpose of this documentation we will illustrate the steps using the SMILE-based service. The PMML-based service can be used by starting Business Central and setting the property as&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;$ ./standalone.sh -Dorg.jbpm.task.prediction.service=PMMLRandomForest&lt;br /&gt;&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;Once Business Central has completed the startup, you can go to&lt;a href="http://localhost:8080/business-central/"&gt; http://localhost:8080/business-central/&lt;/a&gt; and login using the default admin credential &lt;code&gt;wbadmin/wbadmin&lt;/code&gt;. After choosing the default workspace (or creating your own), then select "&lt;i&gt;Import project&lt;/i&gt;" and use the project &lt;code&gt;git&lt;/code&gt; URL:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;https://github.com/ruivieira/jbpm-recommendation-demo-project.git&lt;br /&gt;&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;The repository also contains a REST client (under &lt;code&gt;client&lt;/code&gt;) which allows to add Human Tasks in batch in order to have sufficient data points to train the model, so that we can have meaningful recommendations.&lt;br /&gt;&lt;i&gt;&lt;br /&gt;&lt;/i&gt;&lt;i&gt;NOTE: Before running the REST client, make sure that Business Central is running and the demo project is deployed and also running.&lt;/i&gt;&lt;br /&gt;&lt;br /&gt;The class &lt;code&gt;org.jbpm.recommendation.demo.RESTClient&lt;/code&gt; performs this task and can be executed from the client directory with:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;$ mvn exec:java -Dexec.mainClass="org.jbpm.recommendation.demo.RESTClient"&lt;br /&gt;&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;The prices for Lenovo and Apple laptops are drawn from Normal distributions with respective means of 1500 and 2500 (pictured below). Although the recommendation service is not aware of the deterministic rules we've used to set the task outcome, it will train the model based on the data it receives. The tasks' completion will adhere to the following logic:&lt;br /&gt;&lt;br /&gt;&lt;ul&gt;&lt;li&gt;The purchase of a laptop of brand Lenovo requested by user John or Mary will be approved if the price is around $1500&lt;/li&gt;&lt;li&gt;The purchase of a laptop of brand Apple requested by user John or Mary will be approved if the price is around $2500&lt;/li&gt;&lt;li&gt;The purchase of a laptop of brand Lenovo requested by user John or Mary will be rejected if the price is around $2500&amp;nbsp;&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;&lt;ul&gt;&lt;/ul&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://1.bp.blogspot.com/-wuM-y1CZ3_A/Xa78-qFKCQI/AAAAAAABJP0/PqsgJyqsWLko-j-qDWIDKIkNnGRdbxXiwCLcBGAsYHQ/s1600/prices.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="534" data-original-width="1600" height="209" src="https://1.bp.blogspot.com/-wuM-y1CZ3_A/Xa78-qFKCQI/AAAAAAABJP0/PqsgJyqsWLko-j-qDWIDKIkNnGRdbxXiwCLcBGAsYHQ/s640/prices.png" width="640" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;&lt;br /&gt;The client will then simulate the creation and completion of human tasks, during which the model will be trained.&lt;br /&gt;&lt;br /&gt;&lt;h3&gt;SMILE-based service&lt;/h3&gt;&lt;br /&gt;As we've seen, when creating and completing a batch of tasks (as previously) we are simultaneously training the predictive model. The service implementation is based on a random forest model a popular ensemble learning method.&lt;br /&gt;&lt;br /&gt;When running the &lt;code&gt;RESTClient&lt;/code&gt;, 1200 tasks will be created and completed to allow for a reasonably sized training dataset. The recommendation service initially has a confidence threshold of 1.0 and after a sufficiently large number (arbitrarily chosen as 1200) of observations are used for training, the confidence threshold drops to 0.75. This is simply to demonstrate the two possible actions, &lt;i&gt;i.e.&lt;/i&gt; recommendation without completing and completing the task. This also allows us to avoid any&lt;a href="https://en.wikipedia.org/wiki/Cold_start_(computing)"&gt; cold start&lt;/a&gt; problems.&lt;br /&gt;&lt;br /&gt;After the model is trained with the task from &lt;code&gt;RESTClient&lt;/code&gt;, we will now create a new Human Task.&lt;br /&gt;&lt;br /&gt;If we create a HT requesting the purchase of an "&lt;i&gt;Apple&lt;/i&gt;" laptop from "&lt;i&gt;John&lt;/i&gt;" with the price $2500, we should expect it to be approved.&lt;br /&gt;&lt;br /&gt;If fact, when claiming the task, we can see that the recommendation service recommends the purchase to be approved with a "confidence" of 91%.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://1.bp.blogspot.com/-aphqvmMfkAs/Xa8i2H4jdhI/AAAAAAABJRY/ZxgXRyM3MbktAimGgjl1StXHZWi64ugswCLcBGAsYHQ/s1600/form.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="665" data-original-width="706" height="300" src="https://1.bp.blogspot.com/-aphqvmMfkAs/Xa8i2H4jdhI/AAAAAAABJRY/ZxgXRyM3MbktAimGgjl1StXHZWi64ugswCLcBGAsYHQ/s320/form.png" width="320" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;/div&gt;&lt;br /&gt;&lt;br /&gt;If he now create a task for the request of a "&lt;i&gt;Lenovo&lt;/i&gt;" laptop from "&lt;i&gt;Mary&lt;/i&gt;" with the price $1437, he would expect it to be approved. We can see that this is the case, where the form is filled in by the recommendation service with an approved status with a "confidence" of 86.5%.&lt;br /&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;/div&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://1.bp.blogspot.com/-pqSLRIHEtNI/Xa8jD6QNfsI/AAAAAAABJRc/prCajKd7mh0je1ClPvtbsDOZvVB2JEvcACLcBGAsYHQ/s1600/form2.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="662" data-original-width="693" height="305" src="https://1.bp.blogspot.com/-pqSLRIHEtNI/Xa8jD6QNfsI/AAAAAAABJRc/prCajKd7mh0je1ClPvtbsDOZvVB2JEvcACLcBGAsYHQ/s320/form2.png" width="320" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;&lt;br /&gt;We can also see, as expected, what happens when "&lt;i&gt;John&lt;/i&gt;" tries to order a "&lt;i&gt;Lenovo&lt;/i&gt;" for $2700. The recommendation service fills the form as "not approved" with a "confidence" of 71%.&lt;br /&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://1.bp.blogspot.com/--77n5oCNG50/Xa8jLbsFJZI/AAAAAAABJRg/ZRmVxSufpXUqAYrxbDjc2hOUPw6N7cF5gCLcBGAsYHQ/s1600/form3.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="662" data-original-width="777" height="272" src="https://1.bp.blogspot.com/--77n5oCNG50/Xa8jLbsFJZI/AAAAAAABJRg/ZRmVxSufpXUqAYrxbDjc2hOUPw6N7cF5gCLcBGAsYHQ/s320/form3.png" width="320" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;/div&gt;&lt;br /&gt;&lt;br /&gt;In this service, the confidence threshold is set as 1.0 and as such the task was not closed automatically.&lt;br /&gt;&lt;br /&gt;The minimum number of data points was purposely chosen so that after running the REST client and completing a single task, the service will drop the confidence threshold to 0.75.&lt;br /&gt;&lt;br /&gt;If we complete one of the above tasks manually, the next task you create will be automatically completed if the confidence is above 0.75. For instance, when creating a task we are pretty sure will be approved (&lt;i&gt;e.g.&lt;/i&gt; John purchasing a Lenovo $1500) you can verify that the task is automatically completed.&lt;br /&gt;&lt;br /&gt;&lt;h3&gt;PMML-based service&lt;/h3&gt;&lt;br /&gt;The second example implementation is the PMML-based recommendation service. PMML is a predictive model interchange standard, which allows for a wide variety of models to be reused in different platforms and programming languages.&lt;br /&gt;&lt;br /&gt;The service included in this demo consists of pre-trained model (with a dataset similar to the one generated by &lt;code&gt;RESTClient&lt;/code&gt;) which is executed by a PMML engine. For this demo, the engine used was&lt;a href="https://github.com/jpmml/jpmml-evaluator"&gt; jpmml-evaluator&lt;/a&gt;, the &lt;i&gt;de facto&lt;/i&gt; reference implementation of the PMML specification.&lt;br /&gt;&lt;br /&gt;There are two main differences when comparing this service to the SMILE-based one:&lt;br /&gt;&lt;br /&gt;&lt;ul&gt;&lt;li&gt;The model doesn't need the training phase. The model has been already trained and serialised into the PMML format. This means that we can start using predictions straight away from jBPM.&lt;/li&gt;&lt;li&gt;The &lt;code&gt;train&lt;/code&gt; API method is a no-op in this case. This means that whenever the service's &lt;code&gt;train&lt;/code&gt; method is called, it will not be used for training in this example (only the &lt;code&gt;predict&lt;/code&gt; method is needed for a "read-only" model), as we can see from the figure below.&lt;/li&gt;&lt;/ul&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;/div&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://1.bp.blogspot.com/-sANpab5vAWg/Xa8jzP6e4iI/AAAAAAABJRs/B871rX9kSsIACmwUIAZsU4YDxg7eMMfEgCLcBGAsYHQ/s1600/sequence_pmml.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="839" data-original-width="1213" height="441" src="https://1.bp.blogspot.com/-sANpab5vAWg/Xa8jzP6e4iI/AAAAAAABJRs/B871rX9kSsIACmwUIAZsU4YDxg7eMMfEgCLcBGAsYHQ/s640/sequence_pmml.png" width="640" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;&lt;br /&gt;You can verify that the Business Central workflow is the same as with the SMILE service, although in this case no training is necessary.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;The above instructions on how to setup the demo project are also available in the following video (details are in the subtitles&lt;i&gt;)&lt;/i&gt;:&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;iframe allowfullscreen="" class="YOUTUBE-iframe-video" data-thumbnail-src="https://i.ytimg.com/vi/bqMEPddhKkU/0.jpg" frameborder="0" height="266" src="https://www.youtube.com/embed/bqMEPddhKkU?feature=player_embedded" width="320"&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;br /&gt;&lt;br /&gt;In conclusion, in this post we’ve shown how to use a new API which allows for predictive models to suggest outputs and complete Human Tasks.&lt;br /&gt;&lt;br /&gt;We’ve also shown a project which can use different recommendation service backends simply by registering them with jBPM without any changes to the project.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;Why not create your own jBPM recommendation service using your favourite Machine Learning framework, today?&lt;br /&gt;&lt;br /&gt;&lt;ul&gt;&lt;/ul&gt;&lt;ul&gt;&lt;/ul&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/MIasCImfmlA" height="1" width="1" alt=""/&gt;</content><summary>In this post, we’ll introduce a new jBPM API which allows for predictive models to be trained with Human Tasks (HT) data and for HT to incorporate model predictions as outputs and complete HT without user interaction. This API will allow you to add Machine Learning capabilities to your jBPM project by being able to use, for instance, models trained with historical task data to recommend the most l...</summary><dc:creator>Rui Vieira</dc:creator><dc:date>2019-10-22T16:58:00Z</dc:date><feedburner:origLink>http://mswiderski.blogspot.com/2019/10/introducing-jbpms-human-task.html</feedburner:origLink></entry><entry><title>Jakarta EE: What’s in store for Enterprise JavaBeans?</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/w1Qa84Huv1Q/" /><category term="EJB Remote" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="Java" scheme="searchisko:content:tags" /><category term="Programming Languages" scheme="searchisko:content:tags" /><category term="Red Hat JBoss Enterprise Application Platform" scheme="searchisko:content:tags" /><author><name>rhsilva</name></author><id>searchisko:content:id:jbossorg_blog-jakarta_ee_what_s_in_store_for_enterprise_javabeans</id><updated>2019-10-22T07:00:49Z</updated><published>2019-10-22T07:00:49Z</published><content type="html">&lt;p&gt;&lt;a href="https://docs.oracle.com/cd/E13222_01/wls/docs100/ejb/deploy.html"&gt;Enterprise JavaBeans (EJB)&lt;/a&gt; has been very important to the Java EE ecosystem and promoted many robust solutions to enterprise problems. Besides that, in the past when integration techniques were not so advanced, EJB did great work with remote EJB, integrating many Java EE applications. However, remote EJB is not necessary anymore, and we have many techniques and tools that are better for doing that. So, does EJB still have a place in this new cloud-native world?&lt;/p&gt; &lt;p&gt;Before writing this post, I did an informal survey via &lt;a href="https://twitter.com/rhuan080/status/1175929075057274882"&gt;Twitter poll&lt;/a&gt; to hear what the community thinks about it. In this article, I&amp;#8217;ll share the results of the survey as well as some discussion that emerged as part of the poll&lt;em&gt;. &lt;/em&gt;Additionally, I&amp;#8217;ll share my opinions on the topic.&lt;span id="more-636847"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;Twitter survey&lt;/h2&gt; &lt;p&gt;Here is the question I asked in the survey along with the results (from 385 respondents):&lt;/p&gt; &lt;p&gt;&lt;em&gt;We had many changes in the Java ecosystem mainly in Java enterprise. But what do you think about the EJB future? Do you think EJB has its place in this new cloud-native world? &lt;/em&gt;&lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;em&gt;Yes, but needs updates &amp;#8230;..&lt;strong&gt;29%&lt;/strong&gt;&lt;/em&gt;&lt;/li&gt; &lt;li&gt;&lt;em&gt;No, EJB is unnecessary &amp;#8230;.&lt;strong&gt;50%&lt;/strong&gt;&lt;/em&gt;&lt;/li&gt; &lt;li&gt;&lt;em&gt;Yes, it&amp;#8217;s very useful &amp;#8230;&amp;#8230;&amp;#8230;&amp;#8230;&lt;strong&gt;17%&lt;/strong&gt;&lt;/em&gt;&lt;/li&gt; &lt;li&gt;&lt;em&gt;Other &amp;#8230;&amp;#8230;&amp;#8230;&amp;#8230;&amp;#8230;&amp;#8230;&amp;#8230;&amp;#8230;&amp;#8230;&amp;#8230;&amp;#8230;..&lt;strong&gt;4%&lt;/strong&gt;&lt;/em&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;As you can see, option 2 is the winner, and the majority of respondents think EJB is unnecessary. However, it&amp;#8217;s the winner with 50% of the vote, which means that 50% of respondents think EJB is necessary in some way or have some other opinion. That&amp;#8217;s not the only interesting thing in this survey, though; the other interesting thing was the discussion emerged from this survey about &lt;em&gt;getting the interesting features from EJB and distributing them to other specs with more affinity.&lt;/em&gt; But before we get into this discussion, I&amp;#8217;ll share my opinion and explain why I think this.&lt;/p&gt; &lt;h2&gt;My vote&lt;/h2&gt; &lt;p&gt;My vote is for option 1 (&lt;em&gt;Yes, but needs updates&lt;/em&gt;), because although EJB is an old technology, it has many features that are useful to the enterprise environment. But EJB can be sanitized to offer these features in a lighter technology. Here&amp;#8217;s a list of EJB&amp;#8217;s interesting features:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Asynchronous invocation:&lt;/strong&gt; Is useful when you want to make a non-blocking call to some method.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Stateless EJBs pool: &lt;/strong&gt;Optimizes memory use, promoting reuse of stateless EJB objects.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;@Startup to call a method at startup time: &lt;/strong&gt;Is useful when we want to execute something at startup time.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;EJB timer: &lt;/strong&gt;Is a good feature to schedule a process to execute according to some configuration.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Singleton: &lt;/strong&gt;Is useful when we want only one instance of an object to all applications. Furthermore, it has the method lock feature that is useful when we need to control concurrent access to some method.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Message-driven bean (MDB): &lt;/strong&gt;Is very useful to consume JMS queues and topics. It promotes a simple interface with a high level of abstraction to consume JMS.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Transaction management: &lt;/strong&gt;Is useful to manage transactions with databases and resources (like JMS). It promotes a high level of abstraction to work with transnational processes.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;These features are useful to the current scenario of the enterprise world, and having these features in a spec-based solution is good for the Java ecosystem. Many people have noted that Spring and other frameworks already have these features, but they are important features to have in a spec-based solution (like Jakarta EE) as well, because spec solutions are multi-vendor solutions and not coupled with a specific vendor.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;The interesting EJB features should survive, whether they have the EJB name or not. The idea of getting the interesting features from EJB and distributing them to other specs with more affinity is amazing and means we will have these important features in the Jakarta EE, but in lighter and more organized APIs. This is a good chance to evolve the Jakarta EE feature set to promote lighter, more cohesive Jakarta EE components and APIs.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F22%2Fjakarta-ee-whats-in-store-for-enterprise-javabeans%2F&amp;#38;linkname=Jakarta%20EE%3A%20What%E2%80%99s%20in%20store%20for%20Enterprise%20JavaBeans%3F" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F22%2Fjakarta-ee-whats-in-store-for-enterprise-javabeans%2F&amp;#38;linkname=Jakarta%20EE%3A%20What%E2%80%99s%20in%20store%20for%20Enterprise%20JavaBeans%3F" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F22%2Fjakarta-ee-whats-in-store-for-enterprise-javabeans%2F&amp;#38;linkname=Jakarta%20EE%3A%20What%E2%80%99s%20in%20store%20for%20Enterprise%20JavaBeans%3F" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F22%2Fjakarta-ee-whats-in-store-for-enterprise-javabeans%2F&amp;#38;linkname=Jakarta%20EE%3A%20What%E2%80%99s%20in%20store%20for%20Enterprise%20JavaBeans%3F" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F22%2Fjakarta-ee-whats-in-store-for-enterprise-javabeans%2F&amp;#38;linkname=Jakarta%20EE%3A%20What%E2%80%99s%20in%20store%20for%20Enterprise%20JavaBeans%3F" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F22%2Fjakarta-ee-whats-in-store-for-enterprise-javabeans%2F&amp;#38;linkname=Jakarta%20EE%3A%20What%E2%80%99s%20in%20store%20for%20Enterprise%20JavaBeans%3F" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F22%2Fjakarta-ee-whats-in-store-for-enterprise-javabeans%2F&amp;#38;linkname=Jakarta%20EE%3A%20What%E2%80%99s%20in%20store%20for%20Enterprise%20JavaBeans%3F" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F22%2Fjakarta-ee-whats-in-store-for-enterprise-javabeans%2F&amp;#038;title=Jakarta%20EE%3A%20What%E2%80%99s%20in%20store%20for%20Enterprise%20JavaBeans%3F" data-a2a-url="https://developers.redhat.com/blog/2019/10/22/jakarta-ee-whats-in-store-for-enterprise-javabeans/" data-a2a-title="Jakarta EE: What’s in store for Enterprise JavaBeans?"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/10/22/jakarta-ee-whats-in-store-for-enterprise-javabeans/"&gt;Jakarta EE: What&amp;#8217;s in store for Enterprise JavaBeans?&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/w1Qa84Huv1Q" height="1" width="1" alt=""/&gt;</content><summary>Enterprise JavaBeans (EJB) has been very important to the Java EE ecosystem and promoted many robust solutions to enterprise problems. Besides that, in the past when integration techniques were not so advanced, EJB did great work with remote EJB, integrating many Java EE applications. However, remote EJB is not necessary anymore, and we have many techniques and tools that are better for doing that...</summary><dc:creator>rhsilva</dc:creator><dc:date>2019-10-22T07:00:49Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2019/10/22/jakarta-ee-whats-in-store-for-enterprise-javabeans/</feedburner:origLink></entry><entry><title>.NET Core 3.0 for Red Hat Enterprise Linux 7 now available</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/md-52msxjlk/" /><category term=".net" scheme="searchisko:content:tags" /><category term=".NET Core" scheme="searchisko:content:tags" /><category term=".NET Core 3.0" scheme="searchisko:content:tags" /><category term="Announcement" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="Red Hat Enterprise Linux" scheme="searchisko:content:tags" /><author><name>Bob Davis</name></author><id>searchisko:content:id:jbossorg_blog-net_core_3_0_for_red_hat_enterprise_linux_7_now_available</id><updated>2019-10-21T15:41:13Z</updated><published>2019-10-21T15:41:13Z</published><content type="html">&lt;p&gt;We are very excited to announce the general availability of .NET Core 3.0 for Red Hat Enterprise Linux 7! .NET Core is the open source, cross-platform .NET platform for &lt;a href="https://developers.redhat.com/topics/microservices/"&gt;building microservices&lt;/a&gt;. .NET Core is designed to provide the best performance at scale for applications that use microservices and &lt;a href="https://developers.redhat.com/topics/containers/"&gt;containers&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;.NET Core 3.0 is available today on Red Hat Enterprise Linux 7 via “yum” in the /dotnet repo, and in container images from the &lt;a href="https://access.redhat.com/containers/#/search/dotnet"&gt;Red Hat Container Container Catalog&lt;/a&gt;. Availability for Red Hat Enterprise Linux 8 will come with the release of RHEL 8.1 in Application Streams.&lt;span id="more-637017"&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;.NET Core 3.0 continues to broaden its support and tools for application development in an open source environment. The latest version of .NET Core includes the following improvements:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Support for C# 8.0, f# 4.7&lt;/li&gt; &lt;li&gt;Support for building Windows desktop applications&lt;/li&gt; &lt;li&gt;Supports netstandard2.1&lt;/li&gt; &lt;li&gt;Native executables for framework-dependent applications&lt;/li&gt; &lt;li&gt;Single-file executables&lt;/li&gt; &lt;li&gt;Trimming applications on publish&lt;/li&gt; &lt;li&gt;Ahead-of-time (AOT) compiled applications&lt;/li&gt; &lt;li&gt;Improved support for containers with low-memory allocation&lt;/li&gt; &lt;li&gt;Fast, built-in JSON support&lt;/li&gt; &lt;li&gt;HTTP/2 support in HttpClient&lt;/li&gt; &lt;li&gt;TPS 1.3 support on Linux systems with OpenSSL 1.1.1&lt;/li&gt; &lt;li&gt;Support for building client-side web apps using Blazor&lt;/li&gt; &lt;li&gt;Create high-performance backend services with gRPC&lt;/li&gt; &lt;li&gt;HTTP/2 enabled by default in Kestrel&lt;/li&gt; &lt;li&gt;Authentication support integration with &lt;a href="https://identityserver.io/"&gt;IdentityServer&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Release and support information&lt;/h2&gt; &lt;p&gt;Developers may use .NET Core 3.0 to develop and deploy applications on:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Red Hat Enterprise Linux&lt;/li&gt; &lt;li&gt;Red Hat Enterprise Linux Atomic Host&lt;/li&gt; &lt;li&gt;Red Hat OpenShift Container Platform&lt;/li&gt; &lt;li&gt;Red Hat OpenShift Online&lt;/li&gt; &lt;li&gt;Red Hat OpenShift Dedicated&lt;/li&gt; &lt;li&gt;Red Hat OpenStack Platform&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;.NET Core 3.0 is a current release, &lt;a href="https://access.redhat.com/support/policy/updates/net-core"&gt;as outlined in our lifecycle documentation&lt;/a&gt;. .NET Core 3.1 will be a long-term supported release. We recommend that you adopt .NET Core 3.0. It will be easy to upgrade from .NET Core 3.0. .NET Core 2.2 (the previous &lt;i&gt;current&lt;/i&gt; release) will be supported through December 23, 2019.&lt;/p&gt; &lt;p&gt;For more information, please visit the following:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;a href="https://access.redhat.com/documentation/en-us/net_core/3.0/html-single/getting_started_guide/index"&gt;Get Started with .NET Core 3.0&lt;/a&gt;!&lt;/li&gt; &lt;li&gt;Visit &lt;a href="http://www.redhatloves.net/"&gt;RedHatLoves.NET&lt;/a&gt;&lt;/li&gt; &lt;li&gt;The Red Hat Developer Program &lt;a href="https://developers.redhat.com/products/dotnet/overview/"&gt;technology page on .NET Core&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/category/programming/dot-net/"&gt;Red Hat Developer blogs&lt;/a&gt; on .NET Core&lt;/li&gt; &lt;li&gt;&lt;a href="https://access.redhat.com/documentation/en-us/net_core/3.0/html-single/release_notes_for_rpms/index"&gt;Product Documentation for .NET Core&lt;/a&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;For complete information on the updates and changes made in this release, please visit the &lt;a href="https://github.com/dotnet/core/blob/master/release-notes/3.0/3.0.0/3.0.0.md"&gt;project page on GitHub&lt;/a&gt;. Any important differences between Red Hat’s official source build and other builds that are available will be &lt;a href="https://developers.redhat.com/products/dotnet/docs-and-apis/"&gt;detailed in our release notes&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F21%2Fnet-core-3-0-for-red-hat-enterprise-linux-7-now-available%2F&amp;#38;linkname=.NET%20Core%203.0%20for%20Red%20Hat%20Enterprise%20Linux%207%20now%20available" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F21%2Fnet-core-3-0-for-red-hat-enterprise-linux-7-now-available%2F&amp;#38;linkname=.NET%20Core%203.0%20for%20Red%20Hat%20Enterprise%20Linux%207%20now%20available" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F21%2Fnet-core-3-0-for-red-hat-enterprise-linux-7-now-available%2F&amp;#38;linkname=.NET%20Core%203.0%20for%20Red%20Hat%20Enterprise%20Linux%207%20now%20available" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F21%2Fnet-core-3-0-for-red-hat-enterprise-linux-7-now-available%2F&amp;#38;linkname=.NET%20Core%203.0%20for%20Red%20Hat%20Enterprise%20Linux%207%20now%20available" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F21%2Fnet-core-3-0-for-red-hat-enterprise-linux-7-now-available%2F&amp;#38;linkname=.NET%20Core%203.0%20for%20Red%20Hat%20Enterprise%20Linux%207%20now%20available" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F21%2Fnet-core-3-0-for-red-hat-enterprise-linux-7-now-available%2F&amp;#38;linkname=.NET%20Core%203.0%20for%20Red%20Hat%20Enterprise%20Linux%207%20now%20available" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F21%2Fnet-core-3-0-for-red-hat-enterprise-linux-7-now-available%2F&amp;#38;linkname=.NET%20Core%203.0%20for%20Red%20Hat%20Enterprise%20Linux%207%20now%20available" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F21%2Fnet-core-3-0-for-red-hat-enterprise-linux-7-now-available%2F&amp;#038;title=.NET%20Core%203.0%20for%20Red%20Hat%20Enterprise%20Linux%207%20now%20available" data-a2a-url="https://developers.redhat.com/blog/2019/10/21/net-core-3-0-for-red-hat-enterprise-linux-7-now-available/" data-a2a-title=".NET Core 3.0 for Red Hat Enterprise Linux 7 now available"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/10/21/net-core-3-0-for-red-hat-enterprise-linux-7-now-available/"&gt;.NET Core 3.0 for Red Hat Enterprise Linux 7 now available&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/md-52msxjlk" height="1" width="1" alt=""/&gt;</content><summary>We are very excited to announce the general availability of .NET Core 3.0 for Red Hat Enterprise Linux 7! .NET Core is the open source, cross-platform .NET platform for building microservices. .NET Core is designed to provide the best performance at scale for applications that use microservices and containers. .NET Core 3.0 is available today on Red Hat Enterprise Linux 7 via “yum” in the /dotnet ...</summary><dc:creator>Bob Davis</dc:creator><dc:date>2019-10-21T15:41:13Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2019/10/21/net-core-3-0-for-red-hat-enterprise-linux-7-now-available/</feedburner:origLink></entry><entry><title>3 steps toward improving container security</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/OH0z1FD1tMI/" /><category term="Containers" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="security" scheme="searchisko:content:tags" /><author><name>David Strom</name></author><id>searchisko:content:id:jbossorg_blog-3_steps_toward_improving_container_security</id><updated>2019-10-21T07:00:12Z</updated><published>2019-10-21T07:00:12Z</published><content type="html">&lt;p&gt;As developers increasingly make use of containers, securing them becomes more and more important. Gartner has named &lt;a href="https://www.csoonline.com/article/3268922/why-securing-containers-and-microservices-is-a-challenge.html"&gt;container security&lt;/a&gt; one of its &lt;a href="https://www.gartner.com/doc/3900996/top--security-projects-"&gt;top 10 concerns for this year&lt;/a&gt; in this report, which isn’t surprising given their popularity in producing lightweight and reusable code and lowering app dev costs.&lt;/p&gt; &lt;p&gt;In this article, I’ll look at the three basic steps involved in container security: securing the build environment, securing the underlying container hosts, and securing the actual content that runs inside each container. To be successful at mastering container security means paying attention to all three of these elements. &lt;span id="more-639107"&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;If you step back a moment, container security isn’t all that different from ordinary application security. If you replace the appropriate words in the above paragraph, you could have written this post 10, 20, or even 30 years ago with a few other modifications. But containers do have a few oddities and new twists that are worth highlighting. To get started, I suggest &lt;a href="https://developers.redhat.com/blog/2018/12/19/security-considerations-for-container-runtimes/"&gt;you listen to the recorded talk by Red Hat’s Dan Walsh about general container security considerations&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;1. Securing the build environment&lt;/h2&gt; &lt;p&gt;Let’s start with securing the build environment itself. As with any app dev process, adding security at the beginning of a project makes the most sense, rather than having to bolt something on after most of the code has been written. Using the right methods from the start increases your effectiveness as a programmer and makes for a smoother application development process.&lt;/p&gt; &lt;p&gt;This first component has three separate pieces of its own: First, you need to&lt;b&gt; understand your DevOps workflows.&lt;/b&gt; This includes how you construct your containers, where you obtain their code, and how often the underlying code changes. One of the attractions of containers is their “just-in-time” aspects, where you can pull code from a variety of online sources. How do you know that this code has been properly vetted for general use, and then how do you know that your own particular DevOps process isn’t introducing some specific corner case that will open up a backdoor? That should be your focus in these workflow exercises.&lt;/p&gt; &lt;p&gt;Part of securing your workflow is being able to use discovery tools (e.g., Red Hat’s Quay.io) to ensure that the containers are managed securely and scale up properly. This tool automatically scans each container for security vulnerabilities. &lt;a href="https://developers.redhat.com/blog/2019/06/26/using-quay-io-to-find-vulnerabilities-in-your-container-images/"&gt;This article walks you through how to use Quay&lt;/a&gt; and what to expect.&lt;/p&gt; &lt;p&gt;The second situation involves &lt;b&gt;examining your access rules and permissions for both users and the actual apps themselves&lt;/b&gt;. If you track security breaches, you will realize this is a common theme just among ordinary SaaS apps. How many unsecured web services storage containers have been leaked online, thanks to no actual password or “access all” permissions that haven’t been locked down? Far too many, and this can be true in the container world, where the number of apps can be overwhelming.&lt;/p&gt; &lt;p&gt;One must-do item is to &lt;strong&gt;examine the level of granularity you’ll need for the appropriate access controls&lt;/strong&gt;, both in terms of delivering the right levels of security for your apps as well as for the ultimate users. Do you know which portions of your code have root-level access? How about which portions &lt;strong&gt;actually need&lt;/strong&gt; root-level access? The different answers could mean a more or less secure container, and the optimum answer is as few as possible, approaching zero. If you use LDAP for your ordinary user and app access controls, you &lt;a href="https://developers.redhat.com/blog/2019/08/02/how-to-configure-ldap-user-authentication-and-rbac-in-red-hat-openshift-3-11/"&gt;might want to review the suggestions in this article about how to validate LDAP parameters&lt;/a&gt; and enable LDAP authentication in &lt;a href="https://developers.redhat.com/openshift/"&gt;Red Hat OpenShift&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Finally, with hardening your build environment there is the &lt;b&gt;ability to use runtime protection&lt;/b&gt;. Like the tools for ordinary apps, some of these tools focus on static scans, while others offer continuous integration using your chosen development environment. The continuous method is better, given the dynamic nature of container code, and it could also be a major time saver when you have to perform an app audit. A good runtime protection container tool should be able to flag abnormal behavior, remediate potential threats, and isolate peculiar events for further forensic analysis.&lt;/p&gt; &lt;h2&gt;2. Securing the underlying container hosts&lt;/h2&gt; &lt;p&gt;Once your build environment is secure, the next step is to harden the underlying hosts that run the container servers and services. Take a closer look at what your container provider offers in the way of security. These options may be part of the native Linux container and OpenShift security features, such as policies to prevent abuse of resources, setting up access control groups, and ensuring that you remove root access everywhere, or at least where it isn’t really needed. Many are the same familiar security practices that are part of the virtual machine world, so they shouldn’t come as a surprise. They just have a slightly different context from what you might have been used to before getting involved with containers. One recommended best practice, for example, is to only run containers with read-only images.&lt;/p&gt; &lt;h2&gt;3. Securing the content that runs inside each container&lt;/h2&gt; &lt;p&gt;The final step is to secure the content that is inside the containers. This isn&amp;#8217;t really all that different from securing ordinary apps but it does have a few oddities. You should limit the various Linux OS features that are running within your container, for example. Linux has a general-purpose, OS-level security screening tool called &lt;a href="https://lwn.net/Articles/656307/"&gt;seccomp that is worth reviewing as well&lt;/a&gt;. You should also enforce image source integrity protection so you can track what content has changed in your containers and know who was responsible.&lt;/p&gt; &lt;p&gt;I realize this is a lot of work, and moreover the work will involve getting familiar with multiple tools and multiple application and container and OS constructs, too. A good place to start is to examine the numerous third-party container security tools. Some of these are available from open source vendors and others from commercial vendors that can also assist in your security journey.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F21%2F3-steps-toward-improving-container-security%2F&amp;#38;linkname=3%20steps%20toward%20improving%20container%20security" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F21%2F3-steps-toward-improving-container-security%2F&amp;#38;linkname=3%20steps%20toward%20improving%20container%20security" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F21%2F3-steps-toward-improving-container-security%2F&amp;#38;linkname=3%20steps%20toward%20improving%20container%20security" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F21%2F3-steps-toward-improving-container-security%2F&amp;#38;linkname=3%20steps%20toward%20improving%20container%20security" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F21%2F3-steps-toward-improving-container-security%2F&amp;#38;linkname=3%20steps%20toward%20improving%20container%20security" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F21%2F3-steps-toward-improving-container-security%2F&amp;#38;linkname=3%20steps%20toward%20improving%20container%20security" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F21%2F3-steps-toward-improving-container-security%2F&amp;#38;linkname=3%20steps%20toward%20improving%20container%20security" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F10%2F21%2F3-steps-toward-improving-container-security%2F&amp;#038;title=3%20steps%20toward%20improving%20container%20security" data-a2a-url="https://developers.redhat.com/blog/2019/10/21/3-steps-toward-improving-container-security/" data-a2a-title="3 steps toward improving container security"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/10/21/3-steps-toward-improving-container-security/"&gt;3 steps toward improving container security&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/OH0z1FD1tMI" height="1" width="1" alt=""/&gt;</content><summary>As developers increasingly make use of containers, securing them becomes more and more important. Gartner has named container security one of its top 10 concerns for this year in this report, which isn’t surprising given their popularity in producing lightweight and reusable code and lowering app dev costs. In this article, I’ll look at the three basic steps involved in container security: securin...</summary><dc:creator>David Strom</dc:creator><dc:date>2019-10-21T07:00:12Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2019/10/21/3-steps-toward-improving-container-security/</feedburner:origLink></entry></feed>
